{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install tensorflow==2.3.0\n",
    "!pip install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sagemaker.tensorflow.serving import TensorFlowModel\n",
    "from sagemaker.multidatamodel import MultiDataModel\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker import get_execution_role\n",
    "from tensorflow.keras import utils\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Setup Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.10\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Using TensorFlow version: 2.3.0]\n",
      "[Using SageMaker version: 2.94.0]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'[Using TensorFlow version: {tf.__version__}]')\n",
    "logger.info(f'[Using SageMaker version: {sagemaker.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Seed for Reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Create Roles, Sessions and Data Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "s3 = session.resource('s3')\n",
    "TF_FRAMEWORK_VERSION = '2.3.0'\n",
    "BUCKET = sagemaker.Session().default_bucket()\n",
    "PREFIX = 'cv-models'\n",
    "MONITORING_FOLDER = 'DEMO-tf2-ModelMonitor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Train - CIFAR-10 Image Classification\n",
    "\n",
    "<p align=\"justify\">First, we will train a Convolutional Neural Network (CNN) model to classify images from the CIFAR-10 dataset. Image classification is the task of assigning a label to an image, from a predefined set of categories. CIFAR-10 is an established CV dataset used for object recognition. It is a subset of the 80 Million Tiny Images dataset and consists of 60,000 (32x32) color images containing 1 of 10 object classes, with 6,000 images per class.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### a) Load Data\n",
    "\n",
    "The first step is to load the pre-shuffled CIFAR-10 dataset into our train and test objects. Luckily, Keras provides the CIFAR dataset for us to load using the `load_data()` method. All we have to do is import keras.datasets and then load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X_train Shape: (50000, 32, 32, 3)\n",
      "y_train Shape: (50000, 1)\n",
      "X_test Shape : (10000, 32, 32, 3)\n",
      "y_test Shape : (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'X_train Shape: {X_train.shape}')\n",
    "logger.info(f'y_train Shape: {y_train.shape}')\n",
    "logger.info(f'X_test Shape : {X_test.shape}')\n",
    "logger.info(f'y_test Shape : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### c) Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Rescale \n",
    "Rescales the images by dividing the pixel values by 255: [0,255] ⇒ [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### One Hot Encode Target Labels\n",
    "One-hot encoding is a process by which categorical variables are converted into a numeric form. One-hot encoding converts the (1 × n) label vector to a label matrix of dimensions (10 × n), where n is the number of sample images. So, if we have 1,000 images in our dataset, the label vector will have the dimensions (1 × 1000). After one-hot encoding, the label matrix dimensions will be (1000 × 10). That’s why, when we define our network architecture in the next step, we will make the output softmax layer contain 10 nodes, where each node represents the probability of each class we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Split Data\n",
    "Break original train set further into train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_validation = X_train[500:], X_train[:500]\n",
    "y_train, y_validation = y_train[500:], y_train[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Save to Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Create a local `data/cifar_10` directory to save the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = './data/cifar_10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(DATASET_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Save train, validation and test sets to local `data` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "np.save(f'{DATASET_PATH}/X_train.npy', X_train)\n",
    "np.save(f'{DATASET_PATH}/y_train.npy', y_train)\n",
    "np.save(f'{DATASET_PATH}/X_validation.npy', X_validation)\n",
    "np.save(f'{DATASET_PATH}/y_validation.npy', y_validation)\n",
    "np.save(f'{DATASET_PATH}/X_test.npy', X_test)\n",
    "np.save(f'{DATASET_PATH}/y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Copy Datasets to S3\n",
    "Copy train, validation and test sets from the local dir to S3, since SageMaker expects datasets to be in S3 for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/cifar_10/X_train.npy to s3://sagemaker-us-east-1-949263681218/cv-models/cifar_10/train/X_train.npy\n",
      "upload: data/cifar_10/y_train.npy to s3://sagemaker-us-east-1-949263681218/cv-models/cifar_10/train/y_train.npy\n",
      "upload: data/cifar_10/X_validation.npy to s3://sagemaker-us-east-1-949263681218/cv-models/cifar_10/validation/X_validation.npy\n",
      "upload: data/cifar_10/y_validation.npy to s3://sagemaker-us-east-1-949263681218/cv-models/cifar_10/validation/y_validation.npy\n",
      "upload: data/cifar_10/X_test.npy to s3://sagemaker-us-east-1-949263681218/cv-models/cifar_10/test/X_test.npy\n",
      "upload: data/cifar_10/y_test.npy to s3://sagemaker-us-east-1-949263681218/cv-models/cifar_10/test/y_test.npy\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./{DATASET_PATH}/X_train.npy s3://{BUCKET}/{PREFIX}/cifar_10/train/\n",
    "!aws s3 cp ./{DATASET_PATH}/y_train.npy s3://{BUCKET}/{PREFIX}/cifar_10/train/\n",
    "!aws s3 cp ./{DATASET_PATH}/X_validation.npy s3://{BUCKET}/{PREFIX}/cifar_10/validation/\n",
    "!aws s3 cp ./{DATASET_PATH}/y_validation.npy s3://{BUCKET}/{PREFIX}/cifar_10/validation/\n",
    "!aws s3 cp ./{DATASET_PATH}/X_test.npy s3://{BUCKET}/{PREFIX}/cifar_10/test/\n",
    "!aws s3 cp ./{DATASET_PATH}/y_test.npy s3://{BUCKET}/{PREFIX}/cifar_10/test/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Create Training Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "train_input = TrainingInput(s3_data=f's3://{BUCKET}/{PREFIX}/cifar_10/train', \n",
    "                            distribution='FullyReplicated', \n",
    "                            content_type='npy')\n",
    "validation_input = TrainingInput(s3_data=f's3://{BUCKET}/{PREFIX}/cifar_10/validation', \n",
    "                                 distribution='FullyReplicated', \n",
    "                                 content_type='npy')\n",
    "test_input = TrainingInput(s3_data=f's3://{BUCKET}/{PREFIX}/cifar_10/test', \n",
    "                           distribution='FullyReplicated', \n",
    "                           content_type='npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "inputs = {'train': train_input, 'val': validation_input, 'test': test_input}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### e) Define Model Architecture & create Training Script\n",
    "\n",
    "We will build a small CNN consisting of three convolutional layers and two dense layers.<br>\n",
    "<b>Note:</b> We will use the ReLU activation function for all the hidden layers. In the last dense layer, we will use a softmax activation function with 10 nodes to return an array of 10 probability scores (summing to 1). Each score will be the probability that the current image belongs to our 10 image classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare a Experiment Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "cifar_experiment = Experiment.create(\n",
    "    experiment_name=\"cifar-10-dataset-experiment\", \n",
    "    description=\"objects\", \n",
    "    sagemaker_boto_client=sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.trial import Trial\n",
    "for num_hidden_channel in [32]:\n",
    "    trial_name = f\"cnn-training-job-{num_hidden_channel}-hidden-channels-{int(time.time())}\"\n",
    "    cnn_trial = Trial.create(\n",
    "        trial_name=trial_name, \n",
    "        experiment_name=cifar_experiment.experiment_name,\n",
    "        sagemaker_boto_client=sm,\n",
    "    )\n",
    "    cnn_trial.add_trial_component(tracker.trial_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### f) Create a TensorFlow Estimator & fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter,  IntegerParameter, HyperparameterTuner\n",
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(1e-4, 1, scaling_type=\"Logarithmic\")\n",
    "#     \"epochs\": IntegerParameter(1,3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'cifar-10'\n",
    "hyperparameters = {'epochs': 1}\n",
    "estimator_parameters = {'entry_point':'cifar_train.py',\n",
    "                        'instance_type': 'ml.m5.2xlarge',\n",
    "                        'instance_count': 1,\n",
    "                        'model_dir': '/opt/ml/model',\n",
    "                        'role': role,\n",
    "#                         'hyperparameters': hyperparameters,\n",
    "                        'output_path': f's3://{BUCKET}/{PREFIX}/cifar_10/out',\n",
    "                        'base_job_name': f'mme-cv-{model_name}',\n",
    "                        'framework_version': TF_FRAMEWORK_VERSION,\n",
    "                        'py_version': 'py37',\n",
    "                        'script_mode': True}\n",
    "model = TensorFlow(**estimator_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"loss\", \"Regex\": \"loss : ([0-9\\\\.]+)\"}]\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    model,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=9,\n",
    "    max_parallel_jobs=5,\n",
    "    objective_type=objective_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit(inputs, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn-training-job-1656309139\n",
      "2022-06-27 05:52:20 Starting - Starting the training job...\n",
      "2022-06-27 05:52:43 Starting - Preparing the instances for trainingProfilerReport-1656309139: InProgress\n",
      "......\n",
      "2022-06-27 05:53:48 Downloading - Downloading input data...\n",
      "2022-06-27 05:54:14 Training - Downloading the training image......\n",
      "2022-06-27 05:55:21 Uploading - Uploading generated training model\n",
      "2022-06-27 05:55:21 Failed - Training job failed\n",
      "\u001b[34m2022-06-27 05:55:05,747 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2022-06-27 05:55:05,754 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-27 05:55:06,164 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-27 05:55:06,264 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-27 05:55:06,280 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-27 05:55:06,290 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"/opt/ml/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"ContentType\": \"npy\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"npy\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"ContentType\": \"npy\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"cnn-training-job-1656309139\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-949263681218/cnn-training-job-1656309139/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cifar_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cifar_train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"/opt/ml/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=cifar_train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"ContentType\":\"npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"ContentType\":\"npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"ContentType\":\"npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"val\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=cifar_train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-949263681218/cnn-training-job-1656309139/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"/opt/ml/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"ContentType\":\"npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"ContentType\":\"npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"ContentType\":\"npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cnn-training-job-1656309139\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-949263681218/cnn-training-job-1656309139/source/sourcedir.tar.gz\",\"module_name\":\"cifar_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cifar_train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"/opt/ml/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 cifar_train.py --model_dir /opt/ml/model\u001b[0m\n",
      "\u001b[34m2022-06-27 05:55:08,369 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/usr/local/bin/python3.7 cifar_train.py --model_dir /opt/ml/model\"\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"cifar_train.py\", line 30, in <module>\n",
      "    logger.addHandler(logging.StreamHandler(sys.stdout))\u001b[0m\n",
      "\u001b[34mNameError: name 'sys' is not defined\u001b[0m\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job cnn-training-job-1656309139: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/usr/local/bin/python3.7 cifar_train.py --model_dir /opt/ml/model\"\nTraceback (most recent call last):\n  File \"cifar_train.py\", line 30, in <module>\n    logger.addHandler(logging.StreamHandler(sys.stdout))\nNameError: name 'sys' is not defined, exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-40963e4ddbfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m\"ExperimentName\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"cifar-10-dataset-experiment\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;34m\"TrialName\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'cnn-training-job-32-hidden-channels-1655871250'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0;34m\"TrialComponentDisplayName\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         })\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1992\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1994\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1995\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3823\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3824\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3825\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3826\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3363\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3364\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3365\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3366\u001b[0m             )\n\u001b[1;32m   3367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job cnn-training-job-1656309139: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/usr/local/bin/python3.7 cifar_train.py --model_dir /opt/ml/model\"\nTraceback (most recent call last):\n  File \"cifar_train.py\", line 30, in <module>\n    logger.addHandler(logging.StreamHandler(sys.stdout))\nNameError: name 'sys' is not defined, exit code: 1"
     ]
    }
   ],
   "source": [
    "cnn_training_job_name = \"cnn-training-job-{}\".format(int(time.time()))\n",
    "print(cnn_training_job_name)\n",
    "model.fit(inputs, job_name=cnn_training_job_name,\n",
    "        experiment_config={\n",
    "            \"ExperimentName\": \"cifar-10-dataset-experiment\", \n",
    "            \"TrialName\": 'cnn-training-job-32-hidden-channels-1655871250',\n",
    "            \"TrialComponentDisplayName\": \"Training\",\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-training-220627-0556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'HyperParameterTuningJobName': 'tensorflow-training-220627-0556',\n",
       " 'HyperParameterTuningJobArn': 'arn:aws:sagemaker:us-east-1:949263681218:hyper-parameter-tuning-job/tensorflow-training-220627-0556',\n",
       " 'HyperParameterTuningJobConfig': {'Strategy': 'Bayesian',\n",
       "  'HyperParameterTuningJobObjective': {'Type': 'Minimize',\n",
       "   'MetricName': 'loss'},\n",
       "  'ResourceLimits': {'MaxNumberOfTrainingJobs': 9,\n",
       "   'MaxParallelTrainingJobs': 3},\n",
       "  'ParameterRanges': {'IntegerParameterRanges': [],\n",
       "   'ContinuousParameterRanges': [{'Name': 'learning_rate',\n",
       "     'MinValue': '0.0001',\n",
       "     'MaxValue': '1',\n",
       "     'ScalingType': 'Logarithmic'}],\n",
       "   'CategoricalParameterRanges': []},\n",
       "  'TrainingJobEarlyStoppingType': 'Off'},\n",
       " 'TrainingJobDefinition': {'StaticHyperParameters': {'_tuning_objective_metric': 'loss',\n",
       "   'model_dir': '\"/opt/ml/model\"',\n",
       "   'sagemaker_container_log_level': '20',\n",
       "   'sagemaker_estimator_class_name': '\"TensorFlow\"',\n",
       "   'sagemaker_estimator_module': '\"sagemaker.tensorflow.estimator\"',\n",
       "   'sagemaker_job_name': '\"mme-cv-cifar-10-2022-06-27-05-56-01-181\"',\n",
       "   'sagemaker_program': '\"cifar_train.py\"',\n",
       "   'sagemaker_region': '\"us-east-1\"',\n",
       "   'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-949263681218/mme-cv-cifar-10-2022-06-27-05-56-01-181/source/sourcedir.tar.gz\"'},\n",
       "  'AlgorithmSpecification': {'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.3.0-cpu-py37',\n",
       "   'TrainingInputMode': 'File',\n",
       "   'MetricDefinitions': [{'Name': 'loss', 'Regex': 'loss : ([0-9\\\\.]+)'},\n",
       "    {'Name': 'ObjectiveMetric', 'Regex': 'loss : ([0-9\\\\.]+)'}]},\n",
       "  'RoleArn': 'arn:aws:iam::949263681218:role/service-role/AmazonSageMaker-ExecutionRole-20220609T100106',\n",
       "  'InputDataConfig': [{'ChannelName': 'train',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://sagemaker-us-east-1-949263681218/cv-models/cifar_10/train',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}},\n",
       "    'ContentType': 'npy'},\n",
       "   {'ChannelName': 'val',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://sagemaker-us-east-1-949263681218/cv-models/cifar_10/validation',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}},\n",
       "    'ContentType': 'npy'},\n",
       "   {'ChannelName': 'test',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://sagemaker-us-east-1-949263681218/cv-models/cifar_10/test',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}},\n",
       "    'ContentType': 'npy'}],\n",
       "  'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-949263681218/cv-models/cifar_10/out'},\n",
       "  'ResourceConfig': {'InstanceType': 'ml.m5.2xlarge',\n",
       "   'InstanceCount': 1,\n",
       "   'VolumeSizeInGB': 30},\n",
       "  'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "  'EnableNetworkIsolation': False,\n",
       "  'EnableInterContainerTrafficEncryption': False,\n",
       "  'EnableManagedSpotTraining': False},\n",
       " 'HyperParameterTuningJobStatus': 'Completed',\n",
       " 'CreationTime': datetime.datetime(2022, 6, 27, 5, 56, 1, 617000, tzinfo=tzlocal()),\n",
       " 'HyperParameterTuningEndTime': datetime.datetime(2022, 6, 27, 6, 11, 12, 380000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2022, 6, 27, 6, 11, 12, 380000, tzinfo=tzlocal()),\n",
       " 'TrainingJobStatusCounters': {'Completed': 9,\n",
       "  'InProgress': 0,\n",
       "  'RetryableError': 0,\n",
       "  'NonRetryableError': 0,\n",
       "  'Stopped': 0},\n",
       " 'ObjectiveStatusCounters': {'Succeeded': 9, 'Pending': 0, 'Failed': 0},\n",
       " 'BestTrainingJob': {'TrainingJobName': 'tensorflow-training-220627-0556-001-17c5ce0a',\n",
       "  'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:949263681218:training-job/tensorflow-training-220627-0556-001-17c5ce0a',\n",
       "  'CreationTime': datetime.datetime(2022, 6, 27, 5, 56, 4, tzinfo=tzlocal()),\n",
       "  'TrainingStartTime': datetime.datetime(2022, 6, 27, 5, 57, 28, tzinfo=tzlocal()),\n",
       "  'TrainingEndTime': datetime.datetime(2022, 6, 27, 6, 0, 30, tzinfo=tzlocal()),\n",
       "  'TrainingJobStatus': 'Completed',\n",
       "  'TunedHyperParameters': {'learning_rate': '0.10827078960526701'},\n",
       "  'FinalHyperParameterTuningJobObjectiveMetric': {'MetricName': 'loss',\n",
       "   'Value': 1.0},\n",
       "  'ObjectiveStatus': 'Succeeded'},\n",
       " 'ResponseMetadata': {'RequestId': 'f5206c1e-9bee-42a9-80cb-6e2a7e954b3c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f5206c1e-9bee-42a9-80cb-6e2a7e954b3c',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '3571',\n",
       "   'date': 'Mon, 27 Jun 2022 09:05:49 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tuner.latest_tuning_job.job_name)\n",
    "boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    ") #tensorflow-training-220627-0556"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents of the recorded experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>SourceArn</th>\n",
       "      <th>SageMaker.ImageUri</th>\n",
       "      <th>SageMaker.InstanceCount</th>\n",
       "      <th>SageMaker.InstanceType</th>\n",
       "      <th>SageMaker.VolumeSizeInGB</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_dir</th>\n",
       "      <th>sagemaker_container_log_level</th>\n",
       "      <th>...</th>\n",
       "      <th>SageMaker.DebugHookOutput - MediaType</th>\n",
       "      <th>SageMaker.DebugHookOutput - Value</th>\n",
       "      <th>SageMaker.ModelArtifact - MediaType</th>\n",
       "      <th>SageMaker.ModelArtifact - Value</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Experiments</th>\n",
       "      <th>normalization_mean</th>\n",
       "      <th>normalization_std</th>\n",
       "      <th>cifar-10-dataset-log - MediaType</th>\n",
       "      <th>cifar-10-dataset-log - Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn-training-job-1655879605-aws-training-job</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:949263681218:train...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.m5.4xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>\"/opt/ml/model\"</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-949263681218/cv-model...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-949263681218/cv-model...</td>\n",
       "      <td>[cnn-training-job-32-hidden-channels-1655871250]</td>\n",
       "      <td>[cifar-10-dataset-experiment]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TrialComponent-2022-06-22-041210-guap</td>\n",
       "      <td>Preprocessing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cnn-training-job-10-hidden-channels-165587124...</td>\n",
       "      <td>[cifar-10-dataset-experiment, cifar-10-dataset...</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.3081</td>\n",
       "      <td>s3/uri</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn-training-job-1655871262-aws-training-job</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:949263681218:train...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.m5.2xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"/opt/ml/model\"</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-949263681218/cv-model...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-949263681218/cv-model...</td>\n",
       "      <td>[cnn-training-job-32-hidden-channels-1655871250]</td>\n",
       "      <td>[cifar-10-dataset-experiment]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             TrialComponentName    DisplayName  \\\n",
       "0  cnn-training-job-1655879605-aws-training-job       Training   \n",
       "1         TrialComponent-2022-06-22-041210-guap  Preprocessing   \n",
       "2  cnn-training-job-1655871262-aws-training-job       Training   \n",
       "\n",
       "                                           SourceArn  \\\n",
       "0  arn:aws:sagemaker:us-east-1:949263681218:train...   \n",
       "1                                                NaN   \n",
       "2  arn:aws:sagemaker:us-east-1:949263681218:train...   \n",
       "\n",
       "                                  SageMaker.ImageUri  SageMaker.InstanceCount  \\\n",
       "0  763104351884.dkr.ecr.us-east-1.amazonaws.com/t...                      1.0   \n",
       "1                                                NaN                      NaN   \n",
       "2  763104351884.dkr.ecr.us-east-1.amazonaws.com/t...                      1.0   \n",
       "\n",
       "  SageMaker.InstanceType  SageMaker.VolumeSizeInGB  epochs        model_dir  \\\n",
       "0          ml.m5.4xlarge                      30.0     3.0  \"/opt/ml/model\"   \n",
       "1                    NaN                       NaN     NaN              NaN   \n",
       "2          ml.m5.2xlarge                      30.0     1.0  \"/opt/ml/model\"   \n",
       "\n",
       "   sagemaker_container_log_level  ... SageMaker.DebugHookOutput - MediaType  \\\n",
       "0                           20.0  ...                                   NaN   \n",
       "1                            NaN  ...                                   NaN   \n",
       "2                           20.0  ...                                   NaN   \n",
       "\n",
       "                   SageMaker.DebugHookOutput - Value  \\\n",
       "0  s3://sagemaker-us-east-1-949263681218/cv-model...   \n",
       "1                                                NaN   \n",
       "2  s3://sagemaker-us-east-1-949263681218/cv-model...   \n",
       "\n",
       "  SageMaker.ModelArtifact - MediaType  \\\n",
       "0                                 NaN   \n",
       "1                                 NaN   \n",
       "2                                 NaN   \n",
       "\n",
       "                     SageMaker.ModelArtifact - Value  \\\n",
       "0  s3://sagemaker-us-east-1-949263681218/cv-model...   \n",
       "1                                                NaN   \n",
       "2  s3://sagemaker-us-east-1-949263681218/cv-model...   \n",
       "\n",
       "                                              Trials  \\\n",
       "0   [cnn-training-job-32-hidden-channels-1655871250]   \n",
       "1  [cnn-training-job-10-hidden-channels-165587124...   \n",
       "2   [cnn-training-job-32-hidden-channels-1655871250]   \n",
       "\n",
       "                                         Experiments normalization_mean  \\\n",
       "0                      [cifar-10-dataset-experiment]                NaN   \n",
       "1  [cifar-10-dataset-experiment, cifar-10-dataset...             0.1307   \n",
       "2                      [cifar-10-dataset-experiment]                NaN   \n",
       "\n",
       "  normalization_std cifar-10-dataset-log - MediaType  \\\n",
       "0               NaN                              NaN   \n",
       "1            0.3081                           s3/uri   \n",
       "2               NaN                              NaN   \n",
       "\n",
       "  cifar-10-dataset-log - Value  \n",
       "0                          NaN  \n",
       "1                       random  \n",
       "2                          NaN  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name='cifar-10-dataset-experiment',\n",
    "    sort_by=\"metrics.test:accuracy.max\",\n",
    "    sort_order=\"Descending\",\n",
    "    metric_names=['test:accuracy'],\n",
    "   # parameter_names=['hidden_channels', 'epochs', 'dropout', 'optimizer']\n",
    ")\n",
    "analytic_table = trial_component_analytics.dataframe()\n",
    "analytic_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "from sagemaker.analytics import ExperimentAnalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics = TrainingJobAnalytics(training_job_name = 'cnn-training-job-1655871262', metric_names=['test:accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_sage_client': <botocore.client.SageMaker at 0x7f6cb0c3f8d0>,\n",
       " '_cloudwatch': <botocore.client.CloudWatch at 0x7f6cb13a02e8>,\n",
       " '_training_job_name': 'cnn-training-job-1655871262',\n",
       " '_start_time': None,\n",
       " '_end_time': None,\n",
       " '_period': 60,\n",
       " '_metric_names': ['test:accuracy'],\n",
       " '_dataframe': None,\n",
       " '_data': defaultdict(list, {}),\n",
       " '_time_interval': {'start_time': datetime.datetime(2022, 6, 22, 4, 15, 56, 247000, tzinfo=tzlocal()),\n",
       "  'end_time': datetime.datetime(2022, 6, 22, 4, 20, 6, 584000, tzinfo=tzlocal())}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytics.__dict__ #['_cloudwatch'].list_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cleanup_sme_sdk(experiment):\n",
    "#     for trial_summary in experiment.list_trials():\n",
    "#         trial = Trial.load(trial_name=trial_summary.trial_name)\n",
    "#         for trial_component_summary in trial.list_trial_components():\n",
    "#             tc = TrialComponent.load(\n",
    "#                 trial_component_name=trial_component_summary.trial_component_name)\n",
    "#             trial.remove_trial_component(tc)\n",
    "#             try:\n",
    "#                 # comment out to keep trial components\n",
    "#                 tc.delete()\n",
    "#             except:\n",
    "#                 # tc is associated with another trial\n",
    "#                 continue\n",
    "#             # to prevent throttling\n",
    "#             time.sleep(.5)\n",
    "#         trial.delete()\n",
    "#         experiment_name = experiment.experiment_name\n",
    "#     experiment.delete()\n",
    "#     print(f\"\\nExperiment {experiment_name} deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup_sme_sdk('cifar-10-dataset-experiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD TRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f's3://{BUCKET}/cv-models/cifar_10/out/cnn-training-job-1655978931/output/model.tar.gz'\n",
    "# model_path = f's3://{BUCKET}/cifar_10/out/tensorflow-training-220627-0556-001-17c5ce0a/output/model.tar.gz'\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "\n",
    "model = TensorFlowModel(model_data=model_path, role=role, framework_version=\"2.3.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "data_capture_prefix = \"{}/monitoring/datacapture/\".format(MONITORING_FOLDER)\n",
    "s3_capture_upload_path = \"s3://{}/{}\".format(BUCKET, data_capture_prefix)\n",
    "\n",
    "data_capture_configuration=DataCaptureConfig(\n",
    "        enable_capture=True, sampling_percentage=100, destination_s3_uri=s3_capture_upload_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-06-27 06:00:30 Starting - Preparing the instances for training\n",
      "2022-06-27 06:00:30 Downloading - Downloading input data\n",
      "2022-06-27 06:00:30 Training - Training image download completed. Training in progress.\n",
      "2022-06-27 06:00:30 Uploading - Uploading generated training model\n",
      "2022-06-27 06:00:30 Completed - Training job completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------!\n",
      "Successfully deployed at tensorflow-cv-1656312038...\n"
     ]
    }
   ],
   "source": [
    "endpoint_name=f'tensorflow-cv-{int(time.time())}'\n",
    "predictor = tuner.deploy(initial_instance_count=1,\n",
    "            #model.deploy(initial_instance_count=1,\n",
    "                       instance_type='ml.m5.xlarge',\n",
    "                       endpoint_name=endpoint_name,\n",
    " data_capture_config = data_capture_configuration)\n",
    "print(f\"\\nSuccessfully deployed at {endpoint_name}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointName': 'tensorflow-cv-1656312038',\n",
       " 'EndpointArn': 'arn:aws:sagemaker:us-east-1:949263681218:endpoint/tensorflow-cv-1656312038',\n",
       " 'EndpointConfigName': 'tensorflow-cv-1656312038',\n",
       " 'ProductionVariants': [{'VariantName': 'AllTraffic',\n",
       "   'DeployedImages': [{'SpecifiedImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.3.0-cpu',\n",
       "     'ResolvedImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference@sha256:91ebb7428846c5f7b515d5d9b8389a14c73d0c5d02657f4a6413592124333278',\n",
       "     'ResolutionTime': datetime.datetime(2022, 6, 27, 6, 40, 40, 775000, tzinfo=tzlocal())}],\n",
       "   'CurrentWeight': 1.0,\n",
       "   'DesiredWeight': 1.0,\n",
       "   'CurrentInstanceCount': 1,\n",
       "   'DesiredInstanceCount': 1}],\n",
       " 'DataCaptureConfig': {'EnableCapture': True,\n",
       "  'CaptureStatus': 'Started',\n",
       "  'CurrentSamplingPercentage': 100,\n",
       "  'DestinationS3Uri': 's3://sagemaker-us-east-1-949263681218/DEMO-tf2-ModelMonitor/monitoring/datacapture/'},\n",
       " 'EndpointStatus': 'InService',\n",
       " 'CreationTime': datetime.datetime(2022, 6, 27, 6, 40, 38, 793000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2022, 6, 27, 6, 45, 51, 665000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '1494fa70-15bf-4290-ba97-5a1cc7cfda41',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '1494fa70-15bf-4290-ba97-5a1cc7cfda41',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '933',\n",
       "   'date': 'Mon, 27 Jun 2022 07:24:57 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "sm.describe_endpoint(EndpointName = endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoking the Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from IPython.display import Image\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "CIFAR10_LABELS = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowPredictor\n",
    "predictor = TensorFlowPredictor(endpoint_name = endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('./data/cifar_10/raw_images/jeep.png', target_size=(32, 32))\n",
    "data = img_to_array(img)\n",
    "data = data.astype('float32')\n",
    "data = data / 255.0\n",
    "data = data.reshape(1, 32, 32, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {'instances': data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: [automobile]\n"
     ]
    }
   ],
   "source": [
    "resp = predictor.predict(payload)\n",
    "predicted_label = CIFAR10_LABELS[np.argmax(resp['predictions'])]\n",
    "print(f'Predicted Label: [{predicted_label}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n"
     ]
    }
   ],
   "source": [
    "!ls /opt/ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sending Test Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending test traffic to the endpoint tensorflow-cv-1656312038. \n",
      "Please wait...\n",
      "Done!\n",
      "predictions: \t['frog' 'automobile']\n",
      "CPU times: user 21.7 ms, sys: 0 ns, total: 21.7 ms\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "print(\"Sending test traffic to the endpoint {}. \\nPlease wait...\".format(endpoint_name))\n",
    "\n",
    "flat_list = []\n",
    "for i in range(2):\n",
    "    data = np.array([X_test[i]])\n",
    "    payload = {'instances': data}\n",
    "    resp = predictor.predict(payload)\n",
    "    predicted_label = CIFAR10_LABELS[np.argmax(resp['predictions'])]\n",
    "    flat_list.append(predicted_label)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"Done!\")\n",
    "print(\"predictions: \\t{}\".format(np.array(flat_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Capture Files:\n",
      "DEMO-tf2-ModelMonitor/monitoring/datacapture/\n",
      "sagemaker-us-east-1-949263681218\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.Session().client(\"s3\")\n",
    "result = s3_client.list_objects(Bucket=BUCKET, Prefix=data_capture_prefix)\n",
    "capture_files = [capture_file.get(\"Key\") for capture_file in result.get(\"Contents\")]\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\n \".join(capture_files))\n",
    "print(BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare baseline Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_dataset = \"validation_with_predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train\n",
    "# ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([X_test[i]])\n",
    "    payload = {'instances': data}\n",
    "    resp = predictor.predict(payload)\n",
    "    predicted_label = CIFAR10_LABELS[np.argmax(resp['predictions'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "with open(f\"{validate_dataset}\", \"w\") as baseline_file:\n",
    "    baseline_file.write(\"probability,prediction,label\\n\")  # our header\n",
    "    for i in range(1000):\n",
    "        data = np.array([X_train[i]])\n",
    "        payload = {'instances': data}\n",
    "        resp = predictor.predict(payload)\n",
    "        probability = max(resp['predictions'][0])\n",
    "        prediction = np.argmax(resp['predictions'])\n",
    "        label = y_train[i][0]\n",
    "        \n",
    "        baseline_file.write(f\"{probability},{prediction},{label}\\n\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./validation_with_predictions.csv to s3://sagemaker-us-east-1-949263681218/DEMO-tf2-ModelMonitor/monitoring/baseline/validation_with_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./validation_with_predictions.csv s3://{BUCKET}/DEMO-tf2-ModelMonitor/monitoring/baseline/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL MONITORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_default_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  test-baseline-job-newest\n",
      "Inputs:  [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-949263681218/DEMO-tf2-ModelMonitor/monitoring/baseline/', 'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-949263681218/DEMO-tf2-ModelMonitor/monitoring/baseline/output', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "............................\u001b[34m2022-06-27 07:31:16,452 - matplotlib.font_manager - INFO - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:16.973283: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:16.973314: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:18.519562: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:18.519592: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:18.519611: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-2-114-189.ec2.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:18.519899: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:20,061 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:949263681218:processing-job/test-baseline-job-newest', 'ProcessingJobName': 'test-baseline-job-newest', 'Environment': {'dataset_format': '{\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '156813124566.dkr.ecr.us-east-1.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://sagemaker-us-east-1-949263681218/DEMO-tf2-ModelMonitor/monitoring/baseline/', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinition': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://sagemaker-us-east-1-949263681218/DEMO-tf2-ModelMonitor/monitoring/baseline/output', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 20, 'VolumeKmsKeyId': None}}, 'RoleArn': 'arn:aws:iam::949263681218:role/service-role/AmazonSageMaker-ExecutionRole-20220609T100106', 'StoppingCondition': {'MaxRuntimeInSeconds': 3600}}\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:20,061 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:20,062 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}, \"output_path\": \"/opt/ml/processing/output\", \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:20,062 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:20,062 - bootstrap - INFO - Copy aws jars\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:20,120 - bootstrap - INFO - Copy cluster config\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:20,120 - bootstrap - INFO - Write runtime cluster config\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:20,121 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'hosts': ['algo-1']}\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:20,130 - bootstrap - INFO - Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:20,130 - bootstrap - INFO - Starting spark process for master node algo-1\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:20,130 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:20,593 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.2.114.189\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.0.0\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/had\u001b[0m\n",
      "\u001b[34moop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_312\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:20,600 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:20,603 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-2b11eba2-f92f-400a-b690-d02d6170a079\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,109 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,121 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,122 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,125 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,129 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,129 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,129 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,130 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,167 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,180 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,183 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,187 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,188 INFO blockmanagement.BlockManager: The block deletion will start around 2022 Jun 27 07:31:21\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,189 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,189 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,190 INFO util.GSet: 2.0% max memory 3.1 GB = 63.5 MB\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,190 INFO util.GSet: capacity      = 2^23 = 8388608 entries\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,276 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,281 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,281 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,281 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,281 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,281 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,281 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,281 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,281 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,281 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,281 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,281 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,310 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,310 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,310 INFO util.GSet: 1.0% max memory 3.1 GB = 31.8 MB\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,310 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,312 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,312 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,312 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,313 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,317 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,321 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,322 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,322 INFO util.GSet: 0.25% max memory 3.1 GB = 7.9 MB\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,322 INFO util.GSet: capacity      = 2^20 = 1048576 entries\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,329 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,329 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,329 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,332 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,332 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,333 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,333 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,334 INFO util.GSet: 0.029999999329447746% max memory 3.1 GB = 975.5 KB\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,334 INFO util.GSet: capacity      = 2^17 = 131072 entries\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,356 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1191462369-10.2.114.189-1656315081350\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,370 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,379 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,484 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,496 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,499 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.2.114.189\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:21,517 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:23,588 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:23,588 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:25,671 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:25,671 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:27,758 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:27,758 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:29,868 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:29,868 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:31,947 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:31,948 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:41,953 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:42 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  Main:28 - Start analyzing with args: --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  Main:31 - Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  FileUtil:66 - Read file from path /tmp/spark_job_config.json.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  SparkContext:54 - Running Spark version 2.3.1\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  SparkContext:54 - Submitted application: SageMakerDataAnalyzer\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  SecurityManager:54 - Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  SecurityManager:54 - Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  SecurityManager:54 - Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  SecurityManager:54 - Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 35505.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  SparkEnv:54 - Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  SparkEnv:54 - Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-91637f33-f30d-4dbe-ac27-edf1a9908bfc\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  MemoryStore:54 - MemoryStore started with capacity 1458.6 MB\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  SparkEnv:54 - Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:43 INFO  SparkContext:54 - Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.2.114.189:35505/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1656315103881\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:44 INFO  RMProxy:133 - Connecting to ResourceManager at /10.2.114.189:8032\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:44 INFO  Client:54 - Requesting a new application from cluster with 1 NodeManagers\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:44 INFO  Configuration:2636 - resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:44 INFO  ResourceUtils:427 - Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:44 INFO  Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (15743 MB per container)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:44 INFO  Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:44 INFO  Client:54 - Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:44 INFO  Client:54 - Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:44 INFO  Client:54 - Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:46 WARN  Client:66 - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:47 INFO  Client:54 - Uploading resource file:/tmp/spark-67f51d38-00ba-480a-8e80-f23bf41c10a6/__spark_libs__5675835636343786825.zip -> hdfs://10.2.114.189/user/root/.sparkStaging/application_1656315087070_0001/__spark_libs__5675835636343786825.zip\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:49 INFO  Client:54 - Uploading resource file:/tmp/spark-67f51d38-00ba-480a-8e80-f23bf41c10a6/__spark_conf__1065674791048160528.zip -> hdfs://10.2.114.189/user/root/.sparkStaging/application_1656315087070_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:49 INFO  SecurityManager:54 - Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:49 INFO  SecurityManager:54 - Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:49 INFO  SecurityManager:54 - Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:49 INFO  SecurityManager:54 - Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:49 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:49 INFO  Client:54 - Submitting application application_1656315087070_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:49 INFO  YarnClientImpl:310 - Submitted application application_1656315087070_0001\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:49 INFO  SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1656315087070_0001 and attemptId None\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:50 INFO  Client:54 - Application report for application_1656315087070_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:50 INFO  Client:54 - \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: [Mon Jun 27 07:31:50 +0000 2022] Scheduler has assigned a container for AM, waiting for AM container to be launched\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1656315109512\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1656315087070_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:51 INFO  Client:54 - Application report for application_1656315087070_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:52 INFO  Client:54 - Application report for application_1656315087070_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:53 INFO  Client:54 - Application report for application_1656315087070_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:54 INFO  YarnClientSchedulerBackend:54 - Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1656315087070_0001), /proxy/application_1656315087070_0001\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:54 INFO  Client:54 - Application report for application_1656315087070_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:54 INFO  YarnSchedulerBackend$YarnSchedulerEndpoint:54 - ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:55 INFO  Client:54 - Application report for application_1656315087070_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:55 INFO  Client:54 - \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.2.114.189\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: 0\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1656315109512\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1656315087070_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:55 INFO  YarnClientSchedulerBackend:54 - Application application_1656315087070_0001 has started running.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:55 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45375.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:55 INFO  NettyBlockTransferService:54 - Server created on 10.2.114.189:45375\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:55 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:55 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.2.114.189, 45375, None)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:55 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.2.114.189:45375 with 1458.6 MB RAM, BlockManagerId(driver, 10.2.114.189, 45375, None)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:55 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.2.114.189, 45375, None)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:55 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 10.2.114.189, 45375, None)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:55 INFO  log:192 - Logging initialized @13692ms\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:57 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.2.114.189:35300) with ID 1\u001b[0m\n",
      "\u001b[34m2022-06-27 07:31:57 INFO  BlockManagerMasterEndpoint:54 - Registering block manager algo-1:39845 with 5.8 GB RAM, BlockManagerId(1, algo-1, 39845, None)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:13 INFO  YarnClientSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:14 WARN  SparkContext:66 - Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:14 INFO  DatasetReader:132 - Files to process:List(file:///opt/ml/processing/input/baseline_dataset_input/validation_with_predictions.csv)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:14 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/usr/spark-2.3.1/spark-warehouse').\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:14 INFO  SharedState:54 - Warehouse path is 'file:/usr/spark-2.3.1/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:14 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:15 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#0, None)) > 0)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:15 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:15 INFO  CodeGenerator:54 - Code generated in 163.974567 ms\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:15 INFO  CodeGenerator:54 - Code generated in 25.804331 ms\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:15 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 429.7 KB, free 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:15 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:15 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.2.114.189:45375 (size: 38.3 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:15 INFO  SparkContext:54 - Created broadcast 0 from csv at DatasetReader.scala:83\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:16 INFO  SparkContext:54 - Starting job: csv at DatasetReader.scala:83\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:16 INFO  DAGScheduler:54 - Got job 0 (csv at DatasetReader.scala:83) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:16 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at DatasetReader.scala:83)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:16 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:16 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:16 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at DatasetReader.scala:83), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:16 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 9.4 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:16 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:16 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 10.2.114.189:45375 (size: 4.5 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:16 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:16 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at DatasetReader.scala:83) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:16 INFO  YarnScheduler:54 - Adding task set 0.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:16 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8362 bytes)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:16 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on algo-1:39845 (size: 4.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:17 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on algo-1:39845 (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 1698 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:17 INFO  YarnScheduler:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:17 INFO  DAGScheduler:54 - ResultStage 0 (csv at DatasetReader.scala:83) finished in 1.776 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:17 INFO  DAGScheduler:54 - Job 0 finished: csv at DatasetReader.scala:83, took 1.819029 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:17 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:17 INFO  FileSourceStrategy:54 - Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:17 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:17 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:17 INFO  CodeGenerator:54 - Code generated in 8.753 ms\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:17 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 429.7 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 30\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 8\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 10\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 17\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 3\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 15\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 28\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 1\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 11\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 23\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 26\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 5\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 7\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 2\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 0\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 24\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 27\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 25\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 29\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 14\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 22\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 19\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 9\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 10.2.114.189:45375 (size: 38.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  SparkContext:54 - Created broadcast 2 from csv at DatasetReader.scala:83\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on algo-1:39845 in memory (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on 10.2.114.189:45375 in memory (size: 38.3 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 20\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 6\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 18\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 21\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 4\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 10.2.114.189:45375 in memory (size: 4.5 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on algo-1:39845 in memory (size: 4.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 12\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 16\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  ContextCleaner:54 - Cleaned accumulator 13\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  FileSourceStrategy:54 - Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  FileSourceStrategy:54 - Output Data Schema: struct<probability: string, prediction: string, label: string ... 1 more fields>\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 429.7 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 10.2.114.189:45375 (size: 38.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  SparkContext:54 - Created broadcast 3 from cache at DataAnalyzer.scala:78\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  CodeGenerator:54 - Code generated in 13.099036 ms\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  CodeGenerator:54 - Code generated in 12.996366 ms\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  SparkContext:54 - Starting job: head at DataAnalyzer.scala:81\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  DAGScheduler:54 - Got job 1 (head at DataAnalyzer.scala:81) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (head at DataAnalyzer.scala:81)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[17] at head at DataAnalyzer.scala:81), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 18.7 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 10.2.114.189:45375 (size: 8.6 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[17] at head at DataAnalyzer.scala:81) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  YarnScheduler:54 - Adding task set 1.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8362 bytes)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on algo-1:39845 (size: 8.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on algo-1:39845 (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  BlockManagerInfo:54 - Added rdd_11_0 in memory on algo-1:39845 (size: 19.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 384 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  YarnScheduler:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  DAGScheduler:54 - ResultStage 1 (head at DataAnalyzer.scala:81) finished in 0.424 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  DAGScheduler:54 - Job 1 finished: head at DataAnalyzer.scala:81, took 0.430579 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  DataAnalyzer:89 - The number of columns in the dataframe is 3\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  DataAnalyzer:116 - Number of shards is: 1\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 WARN  Utils:66 - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:18 INFO  CodeGenerator:54 - Code generated in 15.680421 ms\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  DAGScheduler:54 - Registering RDD 22 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  DAGScheduler:54 - Got job 2 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[22] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 47.3 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 18.1 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 10.2.114.189:45375 (size: 18.1 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[22] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  YarnScheduler:54 - Adding task set 2.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8351 bytes)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on algo-1:39845 (size: 18.1 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 824 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  YarnScheduler:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  DAGScheduler:54 - ShuffleMapStage 2 (collect at AnalysisRunner.scala:313) finished in 0.845 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[25] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 55.6 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 10.2.114.189:45375 (size: 20.6 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[25] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  YarnScheduler:54 - Adding task set 3.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on algo-1:39845 (size: 20.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:19 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 10.2.114.189:35300\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 221 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - ResultStage 3 (collect at AnalysisRunner.scala:313) finished in 0.235 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - Job 2 finished: collect at AnalysisRunner.scala:313, took 1.096819 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  YarnScheduler:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  CodeGenerator:54 - Code generated in 16.187354 ms\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - Got job 3 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - Submitting ResultStage 4 (MapPartitionsRDD[34] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 22.8 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.4 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 10.2.114.189:45375 (size: 10.4 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[34] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  YarnScheduler:54 - Adding task set 4.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8362 bytes)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on algo-1:39845 (size: 10.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 180 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  YarnScheduler:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - ResultStage 4 (treeReduce at KLLRunner.scala:107) finished in 0.191 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - Job 3 finished: treeReduce at KLLRunner.scala:107, took 0.195188 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  CodeGenerator:54 - Code generated in 43.689812 ms\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  CodeGenerator:54 - Code generated in 76.243672 ms\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  CodeGenerator:54 - Code generated in 53.188602 ms\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - Registering RDD 39 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - Got job 4 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - Final stage: ResultStage 6 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 5)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 5)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 5 (MapPartitionsRDD[39] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 46.1 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 17.6 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 10.2.114.189:45375 (size: 17.6 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[39] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  YarnScheduler:54 - Adding task set 5.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8351 bytes)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:20 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on algo-1:39845 (size: 17.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 86 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  YarnScheduler:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  DAGScheduler:54 - ShuffleMapStage 5 (collect at AnalysisRunner.scala:313) finished in 0.100 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  DAGScheduler:54 - waiting: Set(ResultStage 6)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  DAGScheduler:54 - Submitting ResultStage 6 (MapPartitionsRDD[42] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 35.4 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.2 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.2.114.189:45375 (size: 12.2 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[42] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  YarnScheduler:54 - Adding task set 6.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on algo-1:39845 (size: 12.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 1 to 10.2.114.189:35300\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 84 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  YarnScheduler:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  DAGScheduler:54 - ResultStage 6 (collect at AnalysisRunner.scala:313) finished in 0.097 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  DAGScheduler:54 - Job 4 finished: collect at AnalysisRunner.scala:313, took 0.207147 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  DAGScheduler:54 - Registering RDD 49 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  DAGScheduler:54 - Got job 5 (countByKey at ColumnProfiler.scala:566) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  DAGScheduler:54 - Final stage: ResultStage 8 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 7 (MapPartitionsRDD[49] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 18.5 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.3 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on 10.2.114.189:45375 (size: 9.3 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  SparkContext:54 - Created broadcast 10 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[49] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  YarnScheduler:54 - Adding task set 7.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8351 bytes)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:21 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on algo-1:39845 (size: 9.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 1124 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  YarnScheduler:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - ShuffleMapStage 7 (countByKey at ColumnProfiler.scala:566) finished in 1.152 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - waiting: Set(ResultStage 8)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - Submitting ResultStage 8 (ShuffledRDD[50] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 3.2 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 1924.0 B, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on 10.2.114.189:45375 (size: 1924.0 B, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 8 (ShuffledRDD[50] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  YarnScheduler:54 - Adding task set 8.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  TaskSetManager:54 - Starting task 0.0 in stage 8.0 (TID 8, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on algo-1:39845 (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 2 to 10.2.114.189:35300\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 8.0 (TID 8) in 47 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  YarnScheduler:54 - Removed TaskSet 8.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - ResultStage 8 (countByKey at ColumnProfiler.scala:566) finished in 0.060 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - Job 5 finished: countByKey at ColumnProfiler.scala:566, took 1.230095 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ConstraintGenerator:45 - Generating Constraints:\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ConstraintGenerator:50 - Constraints: {\n",
      "  \"version\" : 0.0,\n",
      "  \"features\" : [ {\n",
      "    \"name\" : \"probability\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"prediction\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"label\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  } ],\n",
      "  \"monitoring_config\" : {\n",
      "    \"evaluate_constraints\" : \"Enabled\",\n",
      "    \"emit_metrics\" : \"Enabled\",\n",
      "    \"datatype_check_threshold\" : 1.0,\n",
      "    \"domain_content_threshold\" : 1.0,\n",
      "    \"distribution_constraints\" : {\n",
      "      \"perform_comparison\" : \"Enabled\",\n",
      "      \"comparison_threshold\" : 0.1,\n",
      "      \"comparison_method\" : \"Robust\"\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  FileUtil:29 - Write to file constraints.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  StatsGenerator:65 - Generating Stats:\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  CodeGenerator:54 - Code generated in 13.173039 ms\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  CodeGenerator:54 - Code generated in 7.57463 ms\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  SparkContext:54 - Starting job: count at StatsGenerator.scala:67\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - Registering RDD 55 (count at StatsGenerator.scala:67)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - Got job 6 (count at StatsGenerator.scala:67) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - Final stage: ResultStage 10 (count at StatsGenerator.scala:67)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 9 (MapPartitionsRDD[55] at count at StatsGenerator.scala:67), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 19.6 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 9.3 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on 10.2.114.189:45375 (size: 9.3 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  SparkContext:54 - Created broadcast 12 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[55] at count at StatsGenerator.scala:67) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  YarnScheduler:54 - Adding task set 9.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 9, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8351 bytes)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on algo-1:39845 (size: 9.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 9) in 76 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  YarnScheduler:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - ShuffleMapStage 9 (count at StatsGenerator.scala:67) finished in 0.087 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - waiting: Set(ResultStage 10)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - Submitting ResultStage 10 (MapPartitionsRDD[58] at count at StatsGenerator.scala:67), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 7.4 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on 10.2.114.189:45375 (size: 3.8 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  SparkContext:54 - Created broadcast 13 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[58] at count at StatsGenerator.scala:67) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  YarnScheduler:54 - Adding task set 10.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  TaskSetManager:54 - Starting task 0.0 in stage 10.0 (TID 10, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on algo-1:39845 (size: 3.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 3 to 10.2.114.189:35300\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 10.0 (TID 10) in 44 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  YarnScheduler:54 - Removed TaskSet 10.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - ResultStage 10 (count at StatsGenerator.scala:67) finished in 0.056 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  DAGScheduler:54 - Job 6 finished: count at StatsGenerator.scala:67, took 0.151018 s\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 75\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 234\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 299\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 190\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 200\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 319\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 183\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 285\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 216\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 336\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 162\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 256\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 172\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 280\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 52\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 67\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 134\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 260\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 68\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 70\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 324\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 229\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 215\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 126\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 110\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 150\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 197\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 318\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 230\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 61\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 203\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 226\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 267\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 57\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 182\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 242\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 217\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 58\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 165\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 99\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 313\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 273\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 277\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 286\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 211\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 127\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 262\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 42\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 241\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 288\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 272\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 185\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on 10.2.114.189:45375 in memory (size: 12.2 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on algo-1:39845 in memory (size: 12.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 63\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 125\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 247\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 194\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 168\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 328\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 191\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 102\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 186\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 45\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 176\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 295\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 10.2.114.189:45375 in memory (size: 38.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 140\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 47\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 268\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 258\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 266\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 159\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 221\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 309\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 46\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 128\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 141\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 143\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 292\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 248\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 83\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 148\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 220\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 335\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 44\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 136\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned shuffle 0\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 175\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 116\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 314\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 122\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 171\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 177\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 35\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on algo-1:39845 in memory (size: 17.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on 10.2.114.189:45375 in memory (size: 17.6 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 74\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_12_piece0 on 10.2.114.189:45375 in memory (size: 9.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_12_piece0 on algo-1:39845 in memory (size: 9.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 270\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 332\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 123\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 236\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 333\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 227\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 180\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 274\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 113\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 84\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 317\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 195\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 109\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 209\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 263\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 66\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 117\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 158\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 53\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 254\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 49\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 193\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 316\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 32\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 147\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 257\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 202\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 322\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 86\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 219\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 198\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 71\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 207\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 238\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 98\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 214\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on 10.2.114.189:45375 in memory (size: 18.1 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on algo-1:39845 in memory (size: 18.1 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 124\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 91\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 290\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 64\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 253\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 157\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 210\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 304\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 232\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 89\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 115\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 208\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 240\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 111\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_13_piece0 on 10.2.114.189:45375 in memory (size: 3.8 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_13_piece0 on algo-1:39845 in memory (size: 3.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 101\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 223\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 305\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 56\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 330\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 306\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 326\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 129\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 105\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 88\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 114\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 291\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 275\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 320\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on 10.2.114.189:45375 in memory (size: 10.4 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on algo-1:39845 in memory (size: 10.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 170\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 82\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 81\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 225\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 94\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 137\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 189\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned shuffle 2\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 164\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 166\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 65\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 120\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 188\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 59\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 106\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 118\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 323\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 119\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 297\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 138\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 156\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 173\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 72\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 301\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 337\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 250\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 339\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 55\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 155\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 315\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 48\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 334\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 112\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 77\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 153\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 245\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 237\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 284\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 160\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 54\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 255\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 85\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 235\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 264\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 201\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 271\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 187\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned shuffle 3\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 103\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 144\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 178\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 213\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on 10.2.114.189:45375 in memory (size: 9.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on algo-1:39845 in memory (size: 9.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 204\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 239\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 62\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 104\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 307\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 296\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 338\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 169\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 142\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 279\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on 10.2.114.189:45375 in memory (size: 1924.0 B, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on algo-1:39845 in memory (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 149\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 97\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 92\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 340\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 231\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 107\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 310\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 145\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 252\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 303\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 131\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 139\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 287\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 133\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 154\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 311\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 174\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 302\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 206\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 341\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 60\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 34\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 179\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 96\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 308\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 259\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 298\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 329\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 342\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 108\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 343\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 90\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 167\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 261\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 73\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 151\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 192\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on algo-1:39845 in memory (size: 8.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 10.2.114.189:45375 in memory (size: 8.6 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 278\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 276\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 69\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 135\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 43\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 50\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 199\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 181\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 321\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 161\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 121\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 76\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 212\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 224\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 246\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 95\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 281\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 325\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 51\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 79\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 146\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 218\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 293\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 93\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 163\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 184\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 152\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 289\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 196\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 327\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 243\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 312\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 344\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned shuffle 1\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 78\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 80\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 251\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 294\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 282\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 87\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 283\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 331\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 265\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 31\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 205\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 33\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 132\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 222\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 100\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 233\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 269\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on 10.2.114.189:45375 in memory (size: 20.6 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on algo-1:39845 in memory (size: 20.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 228\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 244\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 130\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 300\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:22 INFO  ContextCleaner:54 - Cleaned accumulator 249\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  StatsGenerator:70 - Stats: {\n",
      "  \"version\" : 0.0,\n",
      "  \"dataset\" : {\n",
      "    \"item_count\" : 1000\n",
      "  },\n",
      "  \"features\" : [ {\n",
      "    \"name\" : \"probability\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 1000,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.40341288129299985,\n",
      "      \"sum\" : 403.4128812929998,\n",
      "      \"std_dev\" : 0.1787491646504153,\n",
      "      \"min\" : 0.116330899,\n",
      "      \"max\" : 0.974983633,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.116330899,\n",
      "            \"upper_bound\" : 0.20219617239999998,\n",
      "            \"count\" : 78.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.20219617239999998,\n",
      "            \"upper_bound\" : 0.2880614458,\n",
      "            \"count\" : 246.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2880614458,\n",
      "            \"upper_bound\" : 0.3739267192,\n",
      "            \"count\" : 196.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3739267192,\n",
      "            \"upper_bound\" : 0.4597919926,\n",
      "            \"count\" : 170.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4597919926,\n",
      "            \"upper_bound\" : 0.545657266,\n",
      "            \"count\" : 114.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.545657266,\n",
      "            \"upper_bound\" : 0.6315225394,\n",
      "            \"count\" : 72.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6315225394,\n",
      "            \"upper_bound\" : 0.7173878128000001,\n",
      "            \"count\" : 57.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7173878128000001,\n",
      "            \"upper_bound\" : 0.8032530862,\n",
      "            \"count\" : 27.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8032530862,\n",
      "            \"upper_bound\" : 0.8891183596,\n",
      "            \"count\" : 23.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8891183596,\n",
      "            \"upper_bound\" : 0.974983633,\n",
      "            \"count\" : 17.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.418848723, 0.293665916, 0.476312459, 0.483943522, 0.410109401, 0.624471903, 0.523709118, 0.239331245, 0.548113883, 0.369846463, 0.292844415, 0.50456816, 0.293200314, 0.267177582, 0.216894925, 0.344905525, 0.851576746, 0.271482378, 0.651951551, 0.183913559, 0.325387508, 0.421927303, 0.493726581, 0.232849985, 0.363254249, 0.368751049, 0.287786752, 0.340564281, 0.435965121, 0.575205147, 0.235148728, 0.609551966, 0.282651097, 0.338344336, 0.878485262, 0.346691698, 0.468646169, 0.378560752, 0.298237175, 0.464714557, 0.250745386, 0.381572276, 0.476401508, 0.187947407, 0.370313525, 0.358341604, 0.643788218, 0.640482724, 0.42433852, 0.170261577, 0.523758292, 0.598247468, 0.208859533, 0.351207763, 0.829541624, 0.214716122, 0.23381342, 0.682211876, 0.266819239, 0.239991859, 0.258536488, 0.429027498, 0.868509293, 0.330089688, 0.655138671, 0.281656146, 0.811240375, 0.434923649, 0.578949094, 0.242265925, 0.243808046, 0.247460738, 0.410413682, 0.528194368, 0.871230185, 0.279762596, 0.282310456, 0.487734, 0.386911362, 0.269069135, 0.312151253, 0.520032167, 0.252642751, 0.448103249, 0.148582533, 0.340941727, 0.399705768, 0.536146164, 0.350343943, 0.296602428, 0.267973661, 0.216545939, 0.475609, 0.498921216, 0.348315328, 0.912091374, 0.551793396, 0.201527223, 0.286538035, 0.231711611, 0.59507972, 0.326806039, 0.259976596, 0.319868, 0.567851305, 0.265807271, 0.38297987, 0.574195623, 0.452546239, 0.770252705, 0.346398324, 0.257846802, 0.461214453, 0.445994884, 0.290954351, 0.277400702, 0.272815734, 0.595172286, 0.258941799, 0.23525241, 0.389353573, 0.225635141, 0.427377462, 0.598096728, 0.397716641, 0.28252846, 0.31573841, 0.271513462, 0.19396548, 0.5011186, 0.265394837, 0.825985551, 0.177528411, 0.619451642, 0.445232958, 0.48367247, 0.253903747, 0.600025952, 0.685965896, 0.167844772, 0.157042906, 0.529797912, 0.423751116, 0.628467441, 0.32799235, 0.500041306, 0.207908809, 0.358974367, 0.536148727, 0.22493124, 0.644522965, 0.386681408, 0.195704639, 0.489392668, 0.409365714, 0.192920536, 0.502434969, 0.219855264, 0.552064359, 0.136709094, 0.188574821, 0.31806016, 0.410416812, 0.555777371, 0.268553704, 0.423581302, 0.585971773, 0.23768048, 0.361221731, 0.27602452, 0.719144344, 0.892804801, 0.77096051, 0.428669572, 0.306012511, 0.41704455, 0.365992278, 0.24474442, 0.452920586, 0.457217604, 0.336870879, 0.429868221, 0.504076719, 0.412692398, 0.187679559, 0.333300829, 0.241646096, 0.636694968, 0.565056622, 0.277504534, 0.388978243, 0.336117685, 0.290519655, 0.426360965, 0.391892, 0.302841395, 0.275462925, 0.219302014, 0.43448928, 0.401176959, 0.513888359, 0.252335548, 0.406016, 0.408894718, 0.425216973, 0.264705271, 0.387301683, 0.411179572, 0.479664415, 0.276322126, 0.242536753, 0.199102402, 0.276138604, 0.249519527, 0.121153578, 0.380458921, 0.23030664, 0.335467488, 0.116330899, 0.406963766, 0.334753424, 0.266638517, 0.509322941, 0.203534812, 0.145931125, 0.494177341, 0.464392781, 0.418126702, 0.315652907, 0.510070503, 0.503395796, 0.265211523, 0.406219959, 0.454827189, 0.494133562, 0.18081975, 0.2035366, 0.263740361, 0.293982595, 0.452320784, 0.260147929, 0.477207541, 0.217111036, 0.334973335, 0.372455865, 0.238345042, 0.863945603, 0.227556109, 0.864571571, 0.315955192, 0.551475286, 0.152202368, 0.778192282, 0.473818839, 0.737027586, 0.302129, 0.236671224, 0.824712813, 0.421716452, 0.681229, 0.342457473, 0.577817798, 0.217214271, 0.614860177, 0.421092927, 0.418414831, 0.413189471, 0.328931242, 0.50268966, 0.228047118, 0.341876715, 0.442577541, 0.885966122, 0.19828108, 0.349224955, 0.350442052, 0.382972747, 0.743622482, 0.222977743, 0.33445546, 0.306663841, 0.261603028, 0.350072592, 0.459586948, 0.559620559, 0.309376508, 0.630086899, 0.248878106, 0.276541919, 0.243690133, 0.406644344, 0.206690356, 0.442344099, 0.971702337, 0.970519781, 0.337850481, 0.424085051, 0.22130096, 0.158260837, 0.200101674, 0.279640496, 0.179042175, 0.307847977, 0.247198969, 0.21623145, 0.431269407, 0.462580889, 0.683483303, 0.12381006, 0.693369806, 0.276984572, 0.643822372, 0.309344649, 0.347572923, 0.800088763, 0.436424553, 0.263872683, 0.440732569, 0.370065063, 0.222948804, 0.213142172, 0.425102949, 0.654597878, 0.379064798, 0.424131453, 0.565064907, 0.259089798, 0.37253046, 0.778175175, 0.387022078, 0.541121483, 0.245441526, 0.247678816, 0.522105396, 0.502214432, 0.344897032, 0.185214385, 0.262228698, 0.392269641, 0.547066629, 0.416247666, 0.303861588, 0.709318638, 0.407060146, 0.441638798, 0.224441439, 0.25723514, 0.388330251, 0.354005545, 0.278093129, 0.240654126, 0.233489215, 0.280323774, 0.277167261, 0.735175312, 0.404026598, 0.203407362, 0.26924783, 0.246548653, 0.652216196, 0.438066691, 0.3762905, 0.564664245, 0.233878732, 0.376096845, 0.250596553, 0.382467896, 0.270046413, 0.266667604, 0.460635185, 0.776658952, 0.763371825, 0.324801981, 0.608839273, 0.291944802, 0.497557342, 0.434286982, 0.206371516, 0.303530186, 0.31868428, 0.797450304, 0.251106322, 0.276865453, 0.566807389, 0.363054574, 0.645142317, 0.512139261, 0.181993812, 0.448376477, 0.323152333, 0.393448442, 0.637779176, 0.632901669, 0.530625165, 0.461919308, 0.330977172, 0.320823699, 0.152320057, 0.646211743, 0.21150136, 0.411349535, 0.306182742, 0.376528114, 0.381641269, 0.232664511, 0.587545097, 0.556668699, 0.282640517, 0.627645135, 0.674284816, 0.347728789, 0.399501234, 0.152410686, 0.283428639, 0.366011292, 0.306280762, 0.213979498, 0.496960402, 0.479975522, 0.373575062, 0.504967928, 0.23213768, 0.506592, 0.165950879, 0.724705577, 0.316739261, 0.459723324, 0.133778885, 0.302861631, 0.291019976, 0.319622219, 0.279124111, 0.467471689, 0.318709731, 0.283954591, 0.446339369, 0.571107268, 0.34567523, 0.695871651, 0.30688712, 0.468711913, 0.259418935, 0.584166765, 0.467887402, 0.974983633, 0.28669247, 0.22675474, 0.747327507, 0.406755149, 0.405377537, 0.265739948, 0.46822387, 0.260345936, 0.70259887, 0.678064406, 0.194282845, 0.212104842, 0.393136919, 0.556010246, 0.454957038, 0.332258046, 0.341294974, 0.638835728, 0.497988135, 0.298877865, 0.517979741, 0.59874934, 0.203876853, 0.292091846, 0.762959361, 0.206434816, 0.832501173, 0.235335708, 0.58685, 0.375731707, 0.286191493, 0.381906807, 0.330360472, 0.295595855, 0.207989663, 0.32003668, 0.245910466, 0.278430074, 0.751270473, 0.449367583, 0.263843745, 0.262424141, 0.539189458, 0.323118746, 0.165432587, 0.50075841, 0.499772817, 0.25262782, 0.486844271, 0.525884271, 0.361186206, 0.192818448, 0.245940611, 0.24075599, 0.370445, 0.488988072, 0.493673623, 0.2176494, 0.352551669, 0.225992128, 0.377260953, 0.449764073, 0.190520138, 0.467329592, 0.236562297, 0.269785732, 0.907658815, 0.167734087, 0.229330257, 0.156152159, 0.94152844, 0.876650512, 0.225360617, 0.452697575, 0.814825118, 0.359589607, 0.211204246, 0.513829529, 0.458456665, 0.22861436, 0.366957486, 0.300997496, 0.236101687, 0.176432908, 0.354658306, 0.221871778, 0.219309583, 0.68188417, 0.484580606, 0.259941518, 0.148754254, 0.334922105, 0.437546819, 0.270828962, 0.882291079, 0.360019624, 0.65713793, 0.661955, 0.259787261, 0.507938147, 0.437601238, 0.219734132, 0.290271878, 0.34319225, 0.617050469, 0.315123886, 0.361404419, 0.566660523, 0.286961585, 0.265331268, 0.421784312, 0.834122181, 0.156896859, 0.617278159, 0.261076421, 0.506292403, 0.938337326, 0.32180655, 0.282995075, 0.470429838, 0.490503401, 0.341086864, 0.330515027, 0.311909735, 0.23180607, 0.289343685, 0.36206913, 0.344574064, 0.215221196, 0.368567228, 0.316364408, 0.301316142, 0.327857763, 0.214328825, 0.625074267, 0.679888189, 0.583323836, 0.438684046, 0.365570098, 0.342547238, 0.261018634, 0.338327885, 0.239917725, 0.604149222, 0.29269895, 0.483064145, 0.57384181, 0.346602559, 0.215934604, 0.187610447, 0.339582086, 0.708788335, 0.279614806, 0.721445262, 0.475396514, 0.382991076, 0.249234527, 0.557321966, 0.489579439, 0.135230973, 0.375641406, 0.901593804, 0.236280695, 0.196592614, 0.616109431, 0.361854106, 0.545237362, 0.408786476, 0.391892701, 0.630368888, 0.301320642, 0.319660217, 0.542916119, 0.23012799, 0.686128557, 0.182437792, 0.253223866, 0.27590394, 0.258578897, 0.309794188, 0.453230768, 0.375789583, 0.364345104, 0.246098533, 0.358214796, 0.420942, 0.205416396, 0.352408767, 0.436213195, 0.538504303, 0.896609962, 0.255219638, 0.378091365, 0.181871623, 0.329931974, 0.388324797, 0.821254611, 0.366250098, 0.197007746, 0.305432349, 0.266759843, 0.297491193, 0.172925681, 0.441599309, 0.74600637, 0.289058954, 0.506388545, 0.679396391, 0.504748, 0.523458958, 0.531956255, 0.224217191, 0.223568678, 0.224727035, 0.212063193, 0.409945667, 0.193570957, 0.949250817, 0.322590888, 0.272882164, 0.230430976, 0.715526164, 0.183435053, 0.554181457, 0.197597221, 0.557678342, 0.384795099, 0.426565349, 0.683727384, 0.450573981, 0.279138863, 0.29912132, 0.296779186, 0.510870278, 0.392614722, 0.242854133, 0.704296827, 0.199181065, 0.23955299, 0.306056708, 0.453213841, 0.656057537, 0.226494953, 0.223378897, 0.677468717, 0.559323, 0.281246841, 0.447954029, 0.439666182, 0.67742759, 0.372618854, 0.234696671, 0.922109127, 0.769654334, 0.184892938, 0.398750931, 0.226730734, 0.325148851, 0.322110385, 0.472039372, 0.749021292, 0.4428581, 0.48420161, 0.175304, 0.313088715, 0.374591, 0.219785586, 0.180827036, 0.239575982, 0.628193796, 0.39307639, 0.468840748, 0.477138817, 0.931548893, 0.355335087, 0.237915516, 0.294745862, 0.378888845, 0.279978216, 0.395300418, 0.223959789, 0.923239887, 0.196454838, 0.22214514, 0.719670534, 0.392017335, 0.376581401, 0.323844463, 0.679337084, 0.138712227, 0.406463861, 0.528251469, 0.218267262, 0.199942037, 0.300487489, 0.516588926, 0.276537597, 0.437375814, 0.585950494, 0.421710223, 0.188390851, 0.375101566, 0.437781364, 0.226431802, 0.803842425, 0.528526604, 0.594127059, 0.249792457, 0.16458, 0.261976182, 0.277749956, 0.362741202, 0.164432183, 0.322192162, 0.256186455, 0.28515172, 0.808338881, 0.286332697, 0.488711, 0.273758084, 0.314778119, 0.338017285, 0.179648221, 0.261215806, 0.359404564, 0.411300361, 0.441893339, 0.177476302, 0.307805032, 0.538170338, 0.442968607, 0.646842837, 0.401426911, 0.677313209, 0.213430718, 0.714821875, 0.448917568, 0.158124298, 0.44654423, 0.188524172, 0.430756032, 0.390858173, 0.592645466, 0.234915748, 0.184714943, 0.247140095, 0.309035629, 0.223490268, 0.311931878, 0.690274119, 0.195833832, 0.594141603, 0.203774676, 0.568744779, 0.360870391, 0.724709451, 0.601435781, 0.473557353, 0.232684135, 0.22296153, 0.377600789, 0.468772978, 0.456567615, 0.253412962, 0.714218438, 0.573746, 0.674932, 0.426799983, 0.540172696, 0.263723165, 0.247139156, 0.358091205, 0.382556498, 0.198206484, 0.525911331, 0.432510674, 0.302728176, 0.236228526, 0.854673505, 0.502978146, 0.429255694, 0.296558022, 0.226443961, 0.288069516, 0.489348352, 0.347985804, 0.357720017, 0.323277742, 0.17788595, 0.211409897, 0.427445143, 0.355805278, 0.463777512, 0.272961438, 0.32897982, 0.648771703, 0.179018334, 0.379600853, 0.278692514, 0.423796415, 0.351688296, 0.662601292, 0.367117137, 0.338212729, 0.63998872, 0.369933248, 0.533061683, 0.237799436, 0.456979066, 0.240860343, 0.506759226, 0.312930226, 0.534674704, 0.345059663, 0.431578845, 0.36481142, 0.249789298, 0.269121587, 0.52904, 0.520870149, 0.373680025, 0.316549212, 0.357807398, 0.320442051, 0.864484847, 0.262694329, 0.324525476, 0.220417857, 0.297169328, 0.421301454, 0.744941473, 0.551001608, 0.154078498, 0.30198437, 0.339257687, 0.282811642, 0.208737552, 0.764402628, 0.918332398, 0.379004747, 0.259583831, 0.541921854, 0.427912682, 0.647552, 0.514559209, 0.331365436, 0.704231918, 0.397923797, 0.371472865, 0.424538493, 0.266424686, 0.246985018, 0.656318724, 0.716199338, 0.669373, 0.235510722, 0.147894561, 0.231188804, 0.524259508, 0.625703633, 0.192456603, 0.331694365, 0.453880519, 0.934265792, 0.210748151, 0.45951733, 0.473459631, 0.497609824, 0.58524245, 0.591177762, 0.169909388, 0.430387974, 0.871589, 0.485530347, 0.243512884, 0.195541888, 0.527128279, 0.537183642, 0.167992294, 0.363076508, 0.705949306, 0.266885549, 0.334312201, 0.430004478, 0.733123183, 0.193744197, 0.782973945, 0.26134, 0.389306813, 0.475315869, 0.300770849, 0.279208779, 0.339058429, 0.319984257, 0.626237214, 0.257766515, 0.45776388, 0.421804965, 0.27358669, 0.530700386, 0.213072479, 0.556205928, 0.627941608, 0.335250646, 0.563461542, 0.461197197, 0.528976262, 0.264336199, 0.287390918, 0.279174238, 0.346428305, 0.277235091, 0.407405823, 0.229733899, 0.677534699, 0.378382146, 0.336470485, 0.533471286, 0.319141597, 0.642855406, 0.39663887, 0.304883, 0.366670072, 0.259058982, 0.289966285, 0.295259833, 0.334362388, 0.588455796, 0.179147, 0.395279229, 0.177497387, 0.581228614, 0.594088197, 0.276320815, 0.970806658, 0.282486826, 0.375376046, 0.239996329, 0.737169623, 0.51052016, 0.622557759, 0.407078385, 0.880877554, 0.24206239, 0.547715366, 0.25143978, 0.629388154, 0.384152085, 0.680161238, 0.360646069, 0.415466815, 0.397571385, 0.208854437, 0.639857829, 0.237824515 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"prediction\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 1000,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 5.209,\n",
      "      \"sum\" : 5209.0,\n",
      "      \"std_dev\" : 2.7905768220925227,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 9.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 75.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.8,\n",
      "            \"count\" : 78.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.8,\n",
      "            \"upper_bound\" : 2.7,\n",
      "            \"count\" : 49.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.7,\n",
      "            \"upper_bound\" : 3.6,\n",
      "            \"count\" : 87.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.6,\n",
      "            \"upper_bound\" : 4.5,\n",
      "            \"count\" : 52.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.5,\n",
      "            \"upper_bound\" : 5.4,\n",
      "            \"count\" : 177.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 5.4,\n",
      "            \"upper_bound\" : 6.3,\n",
      "            \"count\" : 71.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 6.3,\n",
      "            \"upper_bound\" : 7.2,\n",
      "            \"count\" : 171.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 7.2,\n",
      "            \"upper_bound\" : 8.1,\n",
      "            \"count\" : 104.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 8.1,\n",
      "            \"upper_bound\" : 9.0,\n",
      "            \"count\" : 136.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 7.0, 1.0, 5.0, 8.0, 0.0, 9.0, 1.0, 1.0, 9.0, 8.0, 5.0, 9.0, 9.0, 2.0, 7.0, 5.0, 7.0, 3.0, 8.0, 5.0, 7.0, 5.0, 7.0, 3.0, 8.0, 5.0, 5.0, 8.0, 4.0, 6.0, 9.0, 7.0, 3.0, 2.0, 5.0, 7.0, 9.0, 7.0, 2.0, 0.0, 4.0, 8.0, 5.0, 4.0, 3.0, 6.0, 8.0, 1.0, 5.0, 7.0, 5.0, 7.0, 7.0, 8.0, 8.0, 3.0, 5.0, 0.0, 2.0, 5.0, 4.0, 1.0, 8.0, 3.0, 8.0, 6.0, 8.0, 8.0, 1.0, 5.0, 7.0, 3.0, 6.0, 7.0, 8.0, 7.0, 1.0, 1.0, 1.0, 9.0, 9.0, 4.0, 7.0, 7.0, 7.0, 0.0, 1.0, 6.0, 6.0, 5.0, 9.0, 0.0, 8.0, 9.0, 8.0, 7.0, 8.0, 2.0, 0.0, 1.0, 0.0, 9.0, 5.0, 5.0, 8.0, 0.0, 9.0, 5.0, 7.0, 8.0, 8.0, 3.0, 9.0, 1.0, 1.0, 3.0, 7.0, 1.0, 3.0, 1.0, 8.0, 2.0, 4.0, 7.0, 5.0, 7.0, 3.0, 1.0, 2.0, 5.0, 3.0, 8.0, 7.0, 5.0, 9.0, 5.0, 7.0, 7.0, 5.0, 8.0, 7.0, 7.0, 6.0, 9.0, 9.0, 6.0, 5.0, 5.0, 7.0, 5.0, 0.0, 6.0, 5.0, 7.0, 7.0, 6.0, 8.0, 9.0, 0.0, 7.0, 9.0, 5.0, 7.0, 0.0, 5.0, 5.0, 9.0, 3.0, 9.0, 4.0, 5.0, 7.0, 8.0, 4.0, 6.0, 7.0, 1.0, 4.0, 7.0, 9.0, 7.0, 5.0, 5.0, 9.0, 5.0, 5.0, 7.0, 0.0, 7.0, 2.0, 9.0, 3.0, 4.0, 3.0, 8.0, 0.0, 7.0, 2.0, 0.0, 9.0, 1.0, 6.0, 6.0, 5.0, 8.0, 7.0, 1.0, 8.0, 7.0, 2.0, 4.0, 0.0, 5.0, 2.0, 9.0, 8.0, 6.0, 3.0, 3.0, 9.0, 4.0, 3.0, 7.0, 0.0, 9.0, 5.0, 5.0, 5.0, 3.0, 7.0, 5.0, 0.0, 5.0, 0.0, 5.0, 8.0, 7.0, 3.0, 4.0, 5.0, 3.0, 0.0, 2.0, 0.0, 5.0, 3.0, 7.0, 1.0, 0.0, 8.0, 5.0, 5.0, 0.0, 1.0, 7.0, 5.0, 9.0, 0.0, 2.0, 7.0, 7.0, 8.0, 5.0, 0.0, 4.0, 0.0, 8.0, 5.0, 9.0, 9.0, 6.0, 7.0, 1.0, 8.0, 3.0, 5.0, 3.0, 8.0, 5.0, 4.0, 7.0, 6.0, 0.0, 1.0, 5.0, 3.0, 0.0, 2.0, 5.0, 7.0, 0.0, 9.0, 5.0, 8.0, 7.0, 8.0, 0.0, 5.0, 7.0, 4.0, 4.0, 9.0, 7.0, 9.0, 6.0, 7.0, 5.0, 6.0, 2.0, 5.0, 7.0, 8.0, 1.0, 3.0, 5.0, 9.0, 2.0, 7.0, 6.0, 3.0, 3.0, 5.0, 0.0, 1.0, 9.0, 5.0, 8.0, 7.0, 9.0, 5.0, 5.0, 7.0, 7.0, 1.0, 1.0, 1.0, 6.0, 6.0, 6.0, 5.0, 1.0, 9.0, 7.0, 9.0, 7.0, 5.0, 1.0, 7.0, 9.0, 4.0, 5.0, 3.0, 2.0, 3.0, 5.0, 1.0, 4.0, 5.0, 5.0, 8.0, 9.0, 5.0, 9.0, 6.0, 9.0, 5.0, 8.0, 9.0, 9.0, 3.0, 8.0, 0.0, 5.0, 9.0, 1.0, 7.0, 3.0, 9.0, 3.0, 1.0, 8.0, 7.0, 3.0, 9.0, 3.0, 0.0, 9.0, 2.0, 9.0, 0.0, 1.0, 8.0, 8.0, 9.0, 5.0, 3.0, 6.0, 2.0, 7.0, 6.0, 9.0, 8.0, 0.0, 4.0, 5.0, 8.0, 0.0, 2.0, 5.0, 8.0, 2.0, 0.0, 6.0, 5.0, 6.0, 5.0, 6.0, 9.0, 5.0, 5.0, 6.0, 3.0, 5.0, 3.0, 6.0, 7.0, 7.0, 4.0, 4.0, 6.0, 2.0, 5.0, 5.0, 2.0, 7.0, 9.0, 1.0, 7.0, 8.0, 4.0, 8.0, 3.0, 1.0, 8.0, 7.0, 4.0, 6.0, 1.0, 7.0, 5.0, 2.0, 7.0, 5.0, 9.0, 7.0, 3.0, 9.0, 2.0, 1.0, 4.0, 6.0, 6.0, 9.0, 5.0, 9.0, 1.0, 7.0, 8.0, 7.0, 5.0, 9.0, 8.0, 3.0, 7.0, 0.0, 3.0, 4.0, 9.0, 1.0, 4.0, 1.0, 7.0, 2.0, 0.0, 5.0, 6.0, 5.0, 8.0, 5.0, 0.0, 2.0, 1.0, 5.0, 5.0, 7.0, 3.0, 5.0, 1.0, 9.0, 5.0, 9.0, 7.0, 3.0, 7.0, 7.0, 7.0, 1.0, 5.0, 7.0, 8.0, 7.0, 8.0, 4.0, 3.0, 9.0, 5.0, 6.0, 3.0, 4.0, 7.0, 9.0, 8.0, 7.0, 6.0, 6.0, 5.0, 9.0, 2.0, 7.0, 1.0, 7.0, 4.0, 8.0, 5.0, 9.0, 3.0, 5.0, 9.0, 4.0, 8.0, 5.0, 5.0, 7.0, 9.0, 8.0, 9.0, 7.0, 6.0, 5.0, 9.0, 2.0, 6.0, 1.0, 5.0, 7.0, 4.0, 8.0, 3.0, 8.0, 5.0, 0.0, 7.0, 9.0, 5.0, 9.0, 2.0, 7.0, 6.0, 7.0, 7.0, 2.0, 5.0, 5.0, 7.0, 3.0, 3.0, 3.0, 7.0, 9.0, 1.0, 8.0, 5.0, 9.0, 7.0, 0.0, 3.0, 0.0, 8.0, 5.0, 9.0, 9.0, 5.0, 8.0, 3.0, 3.0, 1.0, 5.0, 7.0, 5.0, 9.0, 7.0, 3.0, 9.0, 9.0, 7.0, 9.0, 8.0, 4.0, 2.0, 5.0, 5.0, 5.0, 9.0, 7.0, 9.0, 9.0, 8.0, 1.0, 5.0, 8.0, 3.0, 5.0, 5.0, 1.0, 6.0, 7.0, 6.0, 3.0, 2.0, 2.0, 0.0, 0.0, 6.0, 5.0, 5.0, 7.0, 5.0, 9.0, 6.0, 2.0, 9.0, 8.0, 0.0, 5.0, 0.0, 1.0, 3.0, 0.0, 4.0, 7.0, 3.0, 8.0, 5.0, 9.0, 5.0, 6.0, 3.0, 7.0, 0.0, 6.0, 5.0, 6.0, 8.0, 7.0, 3.0, 7.0, 8.0, 0.0, 0.0, 7.0, 9.0, 9.0, 5.0, 7.0, 7.0, 6.0, 3.0, 0.0, 8.0, 7.0, 4.0, 8.0, 4.0, 8.0, 4.0, 9.0, 9.0, 5.0, 4.0, 5.0, 9.0, 7.0, 6.0, 3.0, 6.0, 0.0, 9.0, 7.0, 5.0, 2.0, 5.0, 5.0, 5.0, 5.0, 3.0, 0.0, 7.0, 2.0, 3.0, 4.0, 6.0, 2.0, 6.0, 9.0, 0.0, 7.0, 8.0, 1.0, 7.0, 0.0, 7.0, 4.0, 5.0, 9.0, 3.0, 5.0, 7.0, 7.0, 6.0, 8.0, 8.0, 9.0, 1.0, 9.0, 0.0, 1.0, 8.0, 5.0, 7.0, 3.0, 9.0, 9.0, 9.0, 0.0, 5.0, 8.0, 6.0, 1.0, 9.0, 0.0, 8.0, 1.0, 9.0, 9.0, 0.0, 1.0, 4.0, 2.0, 3.0, 5.0, 9.0, 8.0, 9.0, 9.0, 7.0, 5.0, 2.0, 7.0, 4.0, 5.0, 0.0, 5.0, 6.0, 7.0, 5.0, 7.0, 7.0, 9.0, 0.0, 5.0, 5.0, 5.0, 8.0, 2.0, 4.0, 5.0, 5.0, 1.0, 9.0, 9.0, 3.0, 5.0, 5.0, 9.0, 7.0, 3.0, 0.0, 7.0, 5.0, 4.0, 1.0, 1.0, 9.0, 7.0, 7.0, 9.0, 8.0, 7.0, 3.0, 7.0, 5.0, 4.0, 7.0, 4.0, 5.0, 6.0, 3.0, 7.0, 6.0, 0.0, 9.0, 7.0, 9.0, 8.0, 5.0, 7.0, 3.0, 7.0, 7.0, 0.0, 7.0, 5.0, 9.0, 7.0, 6.0, 0.0, 8.0, 1.0, 1.0, 5.0, 0.0, 5.0, 7.0, 1.0, 5.0, 3.0, 5.0, 4.0, 5.0, 7.0, 5.0, 5.0, 3.0, 1.0, 2.0, 5.0, 9.0, 8.0, 5.0, 5.0, 6.0, 9.0, 2.0, 5.0, 1.0, 7.0, 7.0, 6.0, 7.0, 7.0, 9.0, 3.0, 3.0, 4.0, 7.0, 8.0, 0.0, 9.0, 9.0, 9.0, 9.0, 7.0, 8.0, 8.0, 6.0, 4.0, 7.0, 3.0, 7.0, 1.0, 1.0, 8.0, 8.0, 5.0, 5.0, 7.0, 4.0, 8.0, 8.0, 8.0, 0.0, 3.0, 2.0, 6.0, 8.0, 7.0, 4.0, 7.0, 1.0, 2.0, 1.0, 7.0, 7.0, 8.0, 7.0, 2.0, 1.0, 7.0, 1.0, 3.0, 6.0, 1.0, 9.0, 5.0, 0.0, 6.0, 6.0, 3.0, 0.0, 8.0, 2.0, 8.0, 2.0, 9.0, 0.0, 4.0, 6.0, 9.0, 0.0, 8.0, 3.0, 7.0, 9.0, 5.0, 6.0, 9.0, 1.0, 9.0, 9.0, 5.0, 5.0, 5.0, 1.0, 6.0, 7.0, 8.0, 9.0, 7.0, 3.0, 7.0, 5.0, 5.0, 9.0, 0.0, 1.0, 9.0, 2.0, 9.0, 8.0, 7.0, 9.0, 7.0, 9.0, 7.0, 7.0, 1.0, 9.0, 0.0, 7.0, 8.0, 1.0, 9.0, 3.0, 7.0, 6.0, 6.0, 5.0, 5.0, 7.0, 5.0, 8.0, 7.0, 9.0, 0.0, 1.0, 5.0, 3.0, 3.0, 7.0, 3.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"label\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 1000,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 4.583,\n",
      "      \"sum\" : 4583.0,\n",
      "      \"std_dev\" : 2.901225775426655,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 9.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 104.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.8,\n",
      "            \"count\" : 87.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.8,\n",
      "            \"upper_bound\" : 2.7,\n",
      "            \"count\" : 105.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.7,\n",
      "            \"upper_bound\" : 3.6,\n",
      "            \"count\" : 93.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.6,\n",
      "            \"upper_bound\" : 4.5,\n",
      "            \"count\" : 103.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.5,\n",
      "            \"upper_bound\" : 5.4,\n",
      "            \"count\" : 88.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 5.4,\n",
      "            \"upper_bound\" : 6.3,\n",
      "            \"count\" : 106.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 6.3,\n",
      "            \"upper_bound\" : 7.2,\n",
      "            \"count\" : 99.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 7.2,\n",
      "            \"upper_bound\" : 8.1,\n",
      "            \"count\" : 109.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 8.1,\n",
      "            \"upper_bound\" : 9.0,\n",
      "            \"count\" : 106.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 5.0, 8.0, 2.0, 8.0, 0.0, 4.0, 1.0, 8.0, 9.0, 8.0, 2.0, 9.0, 9.0, 2.0, 7.0, 5.0, 7.0, 3.0, 8.0, 8.0, 4.0, 4.0, 2.0, 7.0, 1.0, 6.0, 4.0, 0.0, 4.0, 6.0, 9.0, 7.0, 6.0, 2.0, 5.0, 5.0, 1.0, 7.0, 2.0, 2.0, 2.0, 9.0, 5.0, 4.0, 2.0, 7.0, 8.0, 1.0, 3.0, 4.0, 3.0, 7.0, 6.0, 9.0, 8.0, 0.0, 6.0, 0.0, 2.0, 2.0, 2.0, 1.0, 8.0, 4.0, 0.0, 1.0, 8.0, 8.0, 1.0, 5.0, 7.0, 6.0, 4.0, 5.0, 8.0, 7.0, 1.0, 9.0, 1.0, 9.0, 8.0, 4.0, 7.0, 3.0, 8.0, 8.0, 2.0, 6.0, 6.0, 7.0, 1.0, 6.0, 8.0, 1.0, 9.0, 7.0, 8.0, 3.0, 0.0, 1.0, 0.0, 8.0, 8.0, 3.0, 0.0, 0.0, 1.0, 5.0, 0.0, 8.0, 8.0, 7.0, 9.0, 9.0, 0.0, 9.0, 4.0, 1.0, 3.0, 6.0, 6.0, 4.0, 4.0, 7.0, 5.0, 6.0, 0.0, 8.0, 0.0, 3.0, 2.0, 8.0, 4.0, 6.0, 9.0, 9.0, 7.0, 0.0, 3.0, 3.0, 6.0, 7.0, 4.0, 9.0, 1.0, 6.0, 2.0, 7.0, 2.0, 2.0, 0.0, 6.0, 7.0, 5.0, 7.0, 6.0, 8.0, 9.0, 0.0, 9.0, 4.0, 4.0, 7.0, 0.0, 9.0, 4.0, 9.0, 6.0, 9.0, 4.0, 5.0, 7.0, 9.0, 2.0, 4.0, 5.0, 1.0, 4.0, 3.0, 9.0, 6.0, 5.0, 6.0, 9.0, 3.0, 3.0, 5.0, 0.0, 7.0, 2.0, 1.0, 3.0, 6.0, 4.0, 0.0, 0.0, 2.0, 5.0, 0.0, 1.0, 0.0, 2.0, 3.0, 9.0, 8.0, 4.0, 9.0, 8.0, 0.0, 2.0, 6.0, 4.0, 4.0, 0.0, 1.0, 8.0, 8.0, 3.0, 6.0, 9.0, 6.0, 6.0, 7.0, 8.0, 2.0, 4.0, 5.0, 7.0, 6.0, 5.0, 3.0, 0.0, 5.0, 0.0, 5.0, 0.0, 8.0, 2.0, 6.0, 7.0, 3.0, 8.0, 2.0, 1.0, 7.0, 6.0, 7.0, 1.0, 0.0, 9.0, 5.0, 5.0, 0.0, 1.0, 7.0, 6.0, 9.0, 0.0, 4.0, 7.0, 7.0, 1.0, 5.0, 9.0, 4.0, 0.0, 8.0, 5.0, 9.0, 9.0, 6.0, 7.0, 1.0, 8.0, 3.0, 2.0, 3.0, 8.0, 2.0, 2.0, 4.0, 6.0, 0.0, 0.0, 5.0, 3.0, 8.0, 2.0, 3.0, 7.0, 2.0, 9.0, 3.0, 8.0, 7.0, 8.0, 2.0, 7.0, 9.0, 0.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 6.0, 2.0, 3.0, 2.0, 8.0, 0.0, 5.0, 5.0, 1.0, 4.0, 5.0, 6.0, 6.0, 2.0, 7.0, 0.0, 1.0, 7.0, 7.0, 8.0, 2.0, 9.0, 2.0, 2.0, 4.0, 2.0, 1.0, 1.0, 1.0, 6.0, 6.0, 6.0, 5.0, 1.0, 1.0, 7.0, 0.0, 4.0, 3.0, 3.0, 7.0, 1.0, 2.0, 3.0, 5.0, 5.0, 5.0, 6.0, 1.0, 4.0, 3.0, 7.0, 8.0, 8.0, 3.0, 6.0, 6.0, 2.0, 3.0, 0.0, 9.0, 4.0, 3.0, 8.0, 0.0, 0.0, 1.0, 1.0, 5.0, 4.0, 9.0, 3.0, 1.0, 8.0, 9.0, 3.0, 9.0, 9.0, 2.0, 9.0, 4.0, 8.0, 2.0, 9.0, 8.0, 8.0, 1.0, 5.0, 3.0, 6.0, 8.0, 7.0, 6.0, 9.0, 8.0, 0.0, 6.0, 4.0, 0.0, 0.0, 2.0, 5.0, 8.0, 2.0, 0.0, 2.0, 7.0, 6.0, 9.0, 7.0, 1.0, 5.0, 5.0, 6.0, 6.0, 3.0, 6.0, 2.0, 4.0, 7.0, 0.0, 5.0, 6.0, 4.0, 6.0, 5.0, 2.0, 4.0, 6.0, 1.0, 6.0, 0.0, 4.0, 0.0, 3.0, 1.0, 8.0, 5.0, 4.0, 4.0, 1.0, 7.0, 3.0, 9.0, 4.0, 7.0, 9.0, 7.0, 3.0, 7.0, 2.0, 8.0, 4.0, 6.0, 6.0, 1.0, 2.0, 9.0, 0.0, 4.0, 8.0, 7.0, 3.0, 9.0, 8.0, 7.0, 7.0, 0.0, 2.0, 4.0, 1.0, 1.0, 4.0, 1.0, 5.0, 4.0, 0.0, 5.0, 6.0, 2.0, 8.0, 5.0, 0.0, 2.0, 1.0, 3.0, 5.0, 7.0, 3.0, 5.0, 1.0, 3.0, 5.0, 9.0, 4.0, 3.0, 2.0, 4.0, 4.0, 1.0, 4.0, 2.0, 2.0, 3.0, 8.0, 0.0, 6.0, 8.0, 5.0, 6.0, 6.0, 4.0, 7.0, 1.0, 1.0, 4.0, 6.0, 2.0, 3.0, 9.0, 6.0, 9.0, 1.0, 3.0, 6.0, 8.0, 5.0, 9.0, 6.0, 8.0, 1.0, 6.0, 0.0, 2.0, 3.0, 7.0, 9.0, 0.0, 9.0, 7.0, 6.0, 3.0, 9.0, 2.0, 6.0, 1.0, 6.0, 7.0, 3.0, 8.0, 3.0, 8.0, 3.0, 8.0, 5.0, 9.0, 6.0, 1.0, 2.0, 5.0, 2.0, 1.0, 4.0, 3.0, 7.0, 5.0, 9.0, 3.0, 9.0, 3.0, 2.0, 9.0, 1.0, 8.0, 5.0, 9.0, 7.0, 2.0, 6.0, 0.0, 8.0, 5.0, 7.0, 1.0, 5.0, 8.0, 5.0, 7.0, 1.0, 5.0, 0.0, 3.0, 9.0, 3.0, 6.0, 9.0, 1.0, 3.0, 9.0, 8.0, 2.0, 2.0, 3.0, 2.0, 5.0, 9.0, 7.0, 9.0, 9.0, 8.0, 9.0, 7.0, 0.0, 3.0, 3.0, 2.0, 0.0, 3.0, 7.0, 6.0, 3.0, 3.0, 2.0, 0.0, 6.0, 6.0, 5.0, 5.0, 7.0, 5.0, 9.0, 8.0, 2.0, 9.0, 8.0, 0.0, 4.0, 0.0, 1.0, 2.0, 0.0, 4.0, 7.0, 3.0, 8.0, 5.0, 1.0, 6.0, 6.0, 5.0, 5.0, 4.0, 6.0, 3.0, 6.0, 8.0, 2.0, 3.0, 7.0, 0.0, 7.0, 0.0, 4.0, 1.0, 9.0, 5.0, 7.0, 8.0, 6.0, 6.0, 8.0, 0.0, 7.0, 2.0, 8.0, 4.0, 8.0, 2.0, 0.0, 9.0, 0.0, 0.0, 2.0, 9.0, 6.0, 6.0, 5.0, 6.0, 0.0, 3.0, 7.0, 5.0, 5.0, 7.0, 9.0, 3.0, 4.0, 5.0, 0.0, 5.0, 2.0, 3.0, 2.0, 6.0, 0.0, 4.0, 9.0, 0.0, 7.0, 0.0, 9.0, 7.0, 2.0, 6.0, 4.0, 6.0, 9.0, 5.0, 4.0, 7.0, 0.0, 6.0, 8.0, 8.0, 9.0, 9.0, 9.0, 0.0, 9.0, 8.0, 6.0, 4.0, 8.0, 1.0, 9.0, 1.0, 0.0, 5.0, 8.0, 6.0, 9.0, 6.0, 0.0, 8.0, 1.0, 3.0, 9.0, 4.0, 8.0, 4.0, 3.0, 2.0, 6.0, 0.0, 8.0, 9.0, 9.0, 4.0, 3.0, 0.0, 2.0, 4.0, 4.0, 0.0, 3.0, 5.0, 7.0, 5.0, 7.0, 7.0, 9.0, 0.0, 9.0, 5.0, 3.0, 8.0, 2.0, 4.0, 2.0, 3.0, 1.0, 2.0, 8.0, 9.0, 2.0, 8.0, 1.0, 4.0, 2.0, 0.0, 4.0, 5.0, 4.0, 8.0, 1.0, 7.0, 4.0, 1.0, 1.0, 0.0, 2.0, 7.0, 7.0, 4.0, 4.0, 4.0, 4.0, 8.0, 4.0, 3.0, 6.0, 6.0, 0.0, 1.0, 3.0, 9.0, 8.0, 4.0, 8.0, 9.0, 6.0, 2.0, 0.0, 5.0, 5.0, 9.0, 4.0, 2.0, 0.0, 8.0, 8.0, 0.0, 4.0, 0.0, 7.0, 6.0, 9.0, 5.0, 3.0, 5.0, 4.0, 4.0, 4.0, 4.0, 3.0, 7.0, 9.0, 2.0, 5.0, 1.0, 8.0, 3.0, 2.0, 6.0, 9.0, 6.0, 3.0, 1.0, 7.0, 4.0, 6.0, 3.0, 7.0, 8.0, 6.0, 2.0, 4.0, 6.0, 8.0, 0.0, 1.0, 9.0, 9.0, 1.0, 0.0, 0.0, 8.0, 9.0, 4.0, 7.0, 4.0, 4.0, 1.0, 9.0, 8.0, 8.0, 6.0, 1.0, 7.0, 4.0, 8.0, 8.0, 8.0, 0.0, 5.0, 6.0, 6.0, 8.0, 3.0, 4.0, 4.0, 1.0, 2.0, 1.0, 5.0, 7.0, 1.0, 7.0, 2.0, 8.0, 5.0, 9.0, 5.0, 6.0, 1.0, 9.0, 5.0, 0.0, 4.0, 3.0, 3.0, 0.0, 8.0, 2.0, 8.0, 0.0, 9.0, 0.0, 4.0, 6.0, 9.0, 2.0, 8.0, 2.0, 7.0, 7.0, 2.0, 2.0, 7.0, 1.0, 6.0, 1.0, 3.0, 4.0, 4.0, 8.0, 6.0, 0.0, 1.0, 9.0, 4.0, 2.0, 7.0, 5.0, 3.0, 9.0, 0.0, 1.0, 9.0, 0.0, 9.0, 8.0, 7.0, 0.0, 4.0, 9.0, 0.0, 5.0, 2.0, 1.0, 0.0, 2.0, 8.0, 8.0, 0.0, 5.0, 7.0, 6.0, 6.0, 5.0, 3.0, 7.0, 7.0, 7.0, 4.0, 2.0, 0.0, 1.0, 7.0, 3.0, 2.0, 7.0, 3.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  } ]\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  FileUtil:29 - Write to file statistics.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  YarnClientSchedulerBackend:54 - Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  YarnClientSchedulerBackend:54 - Shutting down all executors\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices\u001b[0m\n",
      "\u001b[34m(serviceOption=None,\n",
      " services=List(),\n",
      " started=false)\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  YarnClientSchedulerBackend:54 - Stopped\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  MemoryStore:54 - MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  BlockManager:54 - BlockManager stopped\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  SparkContext:54 - Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  Main:65 - Completed: Job completed successfully with no violations.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  Main:141 - Write to file /opt/ml/output/message.\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  ShutdownHookManager:54 - Shutdown hook called\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-67f51d38-00ba-480a-8e80-f23bf41c10a6\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-d0e640c1-a053-4a10-9c85-3817fe49f49f\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23,453 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\u001b[0m\n",
      "\u001b[34m2022-06-27 07:32:23,453 - DefaultDataAnalyzer - INFO - Spark job completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.processing.ProcessingJob at 0x7f2155e02790>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GENERATE constraints and statistics\n",
    "baseline_data_uri = f's3://{BUCKET}/{MONITORING_FOLDER}/monitoring/baseline/'\n",
    "baseline_data_output_uri = f's3://{BUCKET}/{MONITORING_FOLDER}/monitoring/baseline/output'\n",
    "my_default_monitor.suggest_baseline(\n",
    "    job_name = 'test-baseline-job-newest',\n",
    "    baseline_dataset=baseline_data_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=baseline_data_output_uri,\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>numerical_statistics.common.num_present</th>\n",
       "      <th>numerical_statistics.common.num_missing</th>\n",
       "      <th>numerical_statistics.mean</th>\n",
       "      <th>numerical_statistics.sum</th>\n",
       "      <th>numerical_statistics.std_dev</th>\n",
       "      <th>numerical_statistics.min</th>\n",
       "      <th>numerical_statistics.max</th>\n",
       "      <th>numerical_statistics.distribution.kll.buckets</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.c</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.k</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>probability</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.403413</td>\n",
       "      <td>403.412881</td>\n",
       "      <td>0.178749</td>\n",
       "      <td>0.116331</td>\n",
       "      <td>0.974984</td>\n",
       "      <td>[{'lower_bound': 0.116330899, 'upper_bound': 0...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.418848723, 0.293665916, 0.476312459, 0.483...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prediction</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.209000</td>\n",
       "      <td>5209.000000</td>\n",
       "      <td>2.790577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.9, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[7.0, 1.0, 5.0, 8.0, 0.0, 9.0, 1.0, 1.0, 9.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>label</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.583000</td>\n",
       "      <td>4583.000000</td>\n",
       "      <td>2.901226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.9, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[5.0, 8.0, 2.0, 8.0, 0.0, 4.0, 1.0, 8.0, 9.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name inferred_type  numerical_statistics.common.num_present  \\\n",
       "0  probability    Fractional                                     1000   \n",
       "1   prediction      Integral                                     1000   \n",
       "2        label      Integral                                     1000   \n",
       "\n",
       "   numerical_statistics.common.num_missing  numerical_statistics.mean  \\\n",
       "0                                        0                   0.403413   \n",
       "1                                        0                   5.209000   \n",
       "2                                        0                   4.583000   \n",
       "\n",
       "   numerical_statistics.sum  numerical_statistics.std_dev  \\\n",
       "0                403.412881                      0.178749   \n",
       "1               5209.000000                      2.790577   \n",
       "2               4583.000000                      2.901226   \n",
       "\n",
       "   numerical_statistics.min  numerical_statistics.max  \\\n",
       "0                  0.116331                  0.974984   \n",
       "1                  0.000000                  9.000000   \n",
       "2                  0.000000                  9.000000   \n",
       "\n",
       "       numerical_statistics.distribution.kll.buckets  \\\n",
       "0  [{'lower_bound': 0.116330899, 'upper_bound': 0...   \n",
       "1  [{'lower_bound': 0.0, 'upper_bound': 0.9, 'cou...   \n",
       "2  [{'lower_bound': 0.0, 'upper_bound': 0.9, 'cou...   \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.c  \\\n",
       "0                                               0.64           \n",
       "1                                               0.64           \n",
       "2                                               0.64           \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.k  \\\n",
       "0                                             2048.0           \n",
       "1                                             2048.0           \n",
       "2                                             2048.0           \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.data  \n",
       "0  [[0.418848723, 0.293665916, 0.476312459, 0.483...  \n",
       "1  [[7.0, 1.0, 5.0, 8.0, 0.0, 9.0, 1.0, 1.0, 9.0,...  \n",
       "2  [[5.0, 8.0, 2.0, 8.0, 0.0, 4.0, 1.0, 8.0, 9.0,...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "baseline_job = my_default_monitor.latest_baselining_job\n",
    "schema_df = pd.io.json.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>completeness</th>\n",
       "      <th>num_constraints.is_non_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>probability</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prediction</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>label</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name inferred_type  completeness  num_constraints.is_non_negative\n",
       "0  probability    Fractional           1.0                             True\n",
       "1   prediction      Integral           1.0                             True\n",
       "2        label      Integral           1.0                             True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraints_df = pd.io.json.json_normalize(\n",
    "    baseline_job.suggested_constraints().body_dict[\"features\"]\n",
    ")\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import json\n",
    "def preprocess_handler(inference_record):\n",
    "    input_data = json.loads(inference_record.endpoint_input.data)\n",
    "    input_data = {f\"feature{str(i).zfill(10)}\": val for i, val in enumerate(input_data)}\n",
    "\n",
    "    output_data = json.loads(inference_record.endpoint_output.data)[\"predictions\"][0][0]\n",
    "    output_data = {\"prediction0\": output_data}\n",
    "\n",
    "    return {**input_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-949263681218/DEMO-tf2-ModelMonitor/monitoring/preprocessor/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "preprocessor_s3_dest_path = f\"s3://{BUCKET}/{MONITORING_FOLDER}/monitoring/preprocessor\"\n",
    "preprocessor_s3_dest = sagemaker.s3.S3Uploader.upload(\"preprocessing.py\", preprocessor_s3_dest_path)\n",
    "print(preprocessor_s3_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "from time import gmtime, strftime\n",
    "\n",
    "s3_report_path = 's3://{BUCKET}/{MONITORING_FOLDER}/monitoring/preprocessor/processed_output'\n",
    "mon_schedule_name = \"DEMO-tf2-model-monitor-schedule-\" + strftime(\"%Y%m%d-%H%M%S\", gmtime())\n",
    "my_default_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name,\n",
    "    endpoint_input=predictor.endpoint,\n",
    "    record_preprocessor_script=preprocessor_s3_dest,\n",
    "    output_s3_uri=s3_report_path,\n",
    "    statistics=my_default_monitor.baseline_statistics(),\n",
    "    constraints=my_default_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Generated constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "baseline_job = my_default_monitor.latest_baselining_job\n",
    "schema_df = pd.io.json.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_df = pd.io.json.json_normalize(\n",
    "    baseline_job.suggested_constraints().body_dict[\"features\"]\n",
    ")\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "sm = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow-cv-1656312038'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Endpoints': [{'EndpointName': 'tensorflow-cv-1656312038',\n",
       "   'EndpointArn': 'arn:aws:sagemaker:us-east-1:949263681218:endpoint/tensorflow-cv-1656312038',\n",
       "   'CreationTime': datetime.datetime(2022, 6, 27, 6, 40, 38, 793000, tzinfo=tzlocal()),\n",
       "   'LastModifiedTime': datetime.datetime(2022, 6, 27, 6, 45, 51, 665000, tzinfo=tzlocal()),\n",
       "   'EndpointStatus': 'InService'},\n",
       "  {'EndpointName': 'tensorflow-cv-1656302831',\n",
       "   'EndpointArn': 'arn:aws:sagemaker:us-east-1:949263681218:endpoint/tensorflow-cv-1656302831',\n",
       "   'CreationTime': datetime.datetime(2022, 6, 27, 4, 7, 12, 465000, tzinfo=tzlocal()),\n",
       "   'LastModifiedTime': datetime.datetime(2022, 6, 27, 4, 13, 30, 653000, tzinfo=tzlocal()),\n",
       "   'EndpointStatus': 'InService'}],\n",
       " 'ResponseMetadata': {'RequestId': '3b6b05b3-a849-49dd-83bf-2691fa56e898',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '3b6b05b3-a849-49dd-83bf-2691fa56e898',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '479',\n",
       "   'date': 'Mon, 27 Jun 2022 07:03:10 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.list_endpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '24a2674f-bfc2-49ac-9dec-99c2b915321c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '24a2674f-bfc2-49ac-9dec-99c2b915321c',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Mon, 27 Jun 2022 07:03:55 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name='tensorflow-cv-1656302831'\n",
    "sm.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'tensorflow-cv-1656312038'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST CODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.tensorflow.model.TensorFlowPredictor at 0x7fb63b2a8b50>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.model_monitor.data_capture_config.DataCaptureConfig at 0x7fb63b53e510>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_capture_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-949263681218/DEMO-tf2-ModelMonitor/monitoring/datacapture'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_capture_config.destination_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MonitoringScheduleSummaries': [{'MonitoringScheduleName': 'DEMO-tf2-model-monitor-schedule-20220627-073726',\n",
       "   'MonitoringScheduleArn': 'arn:aws:sagemaker:us-east-1:949263681218:monitoring-schedule/demo-tf2-model-monitor-schedule-20220627-073726',\n",
       "   'CreationTime': datetime.datetime(2022, 6, 27, 7, 37, 27, 456000, tzinfo=tzlocal()),\n",
       "   'LastModifiedTime': datetime.datetime(2022, 6, 27, 9, 6, 12, 538000, tzinfo=tzlocal()),\n",
       "   'MonitoringScheduleStatus': 'Scheduled',\n",
       "   'EndpointName': 'tensorflow-cv-1656312038',\n",
       "   'MonitoringJobDefinitionName': 'data-quality-job-definition-2022-06-27-07-37-27-181',\n",
       "   'MonitoringType': 'DataQuality'}],\n",
       " 'ResponseMetadata': {'RequestId': 'd079186d-8972-482d-81bd-947dae6efc23',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'd079186d-8972-482d-81bd-947dae6efc23',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '509',\n",
       "   'date': 'Mon, 27 Jun 2022 09:10:56 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.list_monitoring_schedules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MonitoringScheduleArn': 'arn:aws:sagemaker:us-east-1:949263681218:monitoring-schedule/demo-tf2-model-monitor-schedule-20220627-073726',\n",
       " 'MonitoringScheduleName': 'DEMO-tf2-model-monitor-schedule-20220627-073726',\n",
       " 'MonitoringScheduleStatus': 'Scheduled',\n",
       " 'MonitoringType': 'DataQuality',\n",
       " 'CreationTime': datetime.datetime(2022, 6, 27, 7, 37, 27, 456000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2022, 6, 27, 9, 6, 12, 538000, tzinfo=tzlocal()),\n",
       " 'MonitoringScheduleConfig': {'ScheduleConfig': {'ScheduleExpression': 'cron(0 * ? * * *)'},\n",
       "  'MonitoringJobDefinitionName': 'data-quality-job-definition-2022-06-27-07-37-27-181',\n",
       "  'MonitoringType': 'DataQuality'},\n",
       " 'EndpointName': 'tensorflow-cv-1656312038',\n",
       " 'LastMonitoringExecutionSummary': {'MonitoringScheduleName': 'DEMO-tf2-model-monitor-schedule-20220627-073726',\n",
       "  'ScheduledTime': datetime.datetime(2022, 6, 27, 9, 0, tzinfo=tzlocal()),\n",
       "  'CreationTime': datetime.datetime(2022, 6, 27, 9, 5, 50, 205000, tzinfo=tzlocal()),\n",
       "  'LastModifiedTime': datetime.datetime(2022, 6, 27, 9, 6, 12, 523000, tzinfo=tzlocal()),\n",
       "  'MonitoringExecutionStatus': 'Failed',\n",
       "  'EndpointName': 'tensorflow-cv-1656312038',\n",
       "  'FailureReason': 'Job inputs had no data'},\n",
       " 'ResponseMetadata': {'RequestId': '85f15af9-6e46-4480-ba33-c20d71c666fa',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '85f15af9-6e46-4480-ba33-c20d71c666fa',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '921',\n",
       "   'date': 'Mon, 27 Jun 2022 09:11:08 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.describe_monitoring_schedule(MonitoringScheduleName = 'DEMO-tf2-model-monitor-schedule-20220627-073726')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '74d73803-5125-43ad-a548-729023f93df1',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '74d73803-5125-43ad-a548-729023f93df1',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Mon, 27 Jun 2022 07:03:05 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.delete_monitoring_schedule(MonitoringScheduleName = 'DEMO-tf2-model-monitor-schedule-2022-06-27-04-43-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://stackoverflow.com/questions/69179914/how-to-fix-sagemaker-data-quality-monitoring-schedule-job-that-fails-with-failu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/fairness_and_explainability/SageMaker-Model-Monitor-Fairness-and-Explainability.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /opt/ml/input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal error: An error occurred (404) when calling the HeadObject operation: Key \"DEMO-tf2-ModelMonitor/monitoring/ground_truth/\" does not exist\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./{DATASET_PATH}/X_train.npy s3://{BUCKET}/{PREFIX}/cifar_10/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal error: An error occurred (404) when calling the HeadObject operation: Key \"DEMO-tf2-ModelMonitor/monitoring/ground_truth\" does not exist\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://sagemaker-us-east-1-949263681218/DEMO-tf2-ModelMonitor/monitoring/ground_truth/2022/ /opt/ml/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /opt/ml/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
