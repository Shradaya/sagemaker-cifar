{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install tensorflow==2.3.0\n",
    "!pip install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sagemaker.tensorflow.serving import TensorFlowModel\n",
    "from sagemaker.multidatamodel import MultiDataModel\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sagemaker.tuner import ContinuousParameter,  IntegerParameter, HyperparameterTuner\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sagemaker.tensorflow.model import TensorFlowPredictor\n",
    "from IPython.display import Image\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker import get_execution_role\n",
    "from tensorflow.keras import utils\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Setup Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "logger.info(f'[Using TensorFlow version: {tf.__version__}]')\n",
    "logger.info(f'[Using SageMaker version: {sagemaker.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Seed for Reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Create Roles, Sessions and Data Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "s3 = session.resource('s3')\n",
    "TF_FRAMEWORK_VERSION = '2.3.0'\n",
    "BUCKET = sagemaker.Session().default_bucket()\n",
    "PREFIX = 'cv-models'\n",
    "MONITORING_FOLDER = 'DEMO-tf2-ModelMonitor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Load the Cifar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "logger.info(f'X_train Shape: {X_train.shape}')\n",
    "logger.info(f'y_train Shape: {y_train.shape}')\n",
    "logger.info(f'X_test Shape : {X_test.shape}')\n",
    "logger.info(f'y_test Shape : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Rescale \n",
    "Rescales the images by dividing the pixel values by 255: [0,255] ⇒ [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### One Hot Encode Target Labels\n",
    "One-hot encoding is a process by which categorical variables are converted into a numeric form. One-hot encoding converts the (1 × n) label vector to a label matrix of dimensions (10 × n), where n is the number of sample images. So, if we have 1,000 images in our dataset, the label vector will have the dimensions (1 × 1000). After one-hot encoding, the label matrix dimensions will be (1000 × 10). That’s why, when we define our network architecture in the next step, we will make the output softmax layer contain 10 nodes, where each node represents the probability of each class we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Split Data\n",
    "Break original train set further into train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_validation = X_train[500:], X_train[:500]\n",
    "y_train, y_validation = y_train[500:], y_train[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Save to Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Create a local `data/cifar_10` directory to save the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = './data/cifar_10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(DATASET_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Save train, validation and test sets to local `data` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "np.save(f'{DATASET_PATH}/X_train.npy', X_train)\n",
    "np.save(f'{DATASET_PATH}/y_train.npy', y_train)\n",
    "np.save(f'{DATASET_PATH}/X_validation.npy', X_validation)\n",
    "np.save(f'{DATASET_PATH}/y_validation.npy', y_validation)\n",
    "np.save(f'{DATASET_PATH}/X_test.npy', X_test)\n",
    "np.save(f'{DATASET_PATH}/y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Copy Datasets to S3\n",
    "Copy train, validation and test sets from the local dir to S3, since SageMaker expects datasets to be in S3 for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "!aws s3 cp ./{DATASET_PATH}/X_train.npy s3://{BUCKET}/{PREFIX}/cifar_10/train/\n",
    "!aws s3 cp ./{DATASET_PATH}/y_train.npy s3://{BUCKET}/{PREFIX}/cifar_10/train/\n",
    "!aws s3 cp ./{DATASET_PATH}/X_validation.npy s3://{BUCKET}/{PREFIX}/cifar_10/validation/\n",
    "!aws s3 cp ./{DATASET_PATH}/y_validation.npy s3://{BUCKET}/{PREFIX}/cifar_10/validation/\n",
    "!aws s3 cp ./{DATASET_PATH}/X_test.npy s3://{BUCKET}/{PREFIX}/cifar_10/test/\n",
    "!aws s3 cp ./{DATASET_PATH}/y_test.npy s3://{BUCKET}/{PREFIX}/cifar_10/test/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Create Training Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "train_input = TrainingInput(s3_data=f's3://{BUCKET}/{PREFIX}/cifar_10/train', \n",
    "                            distribution='FullyReplicated', \n",
    "                            content_type='npy')\n",
    "validation_input = TrainingInput(s3_data=f's3://{BUCKET}/{PREFIX}/cifar_10/validation', \n",
    "                                 distribution='FullyReplicated', \n",
    "                                 content_type='npy')\n",
    "test_input = TrainingInput(s3_data=f's3://{BUCKET}/{PREFIX}/cifar_10/test', \n",
    "                           distribution='FullyReplicated', \n",
    "                           content_type='npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "inputs = {'train': train_input, 'val': validation_input, 'test': test_input}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare a Experiment Tracker\n",
    "SageMaker Experiment tracker works on a hierarchical model of Experiment, Trial and Trial component respectively.\n",
    "Amazon SageMaker Experiments is a capability of Amazon SageMaker that lets you organize, track, compare, and evaluate your machine learning experiments.\n",
    "A trial consists of one or more trial components, such as a data preprocessing job and a training job.\n",
    "The TrialName is passed on while fitting an ML model such that the job is recorded by the TrialName.\n",
    "\n",
    "An Experiment can be separated for a certain project, while TrialName can be related to varying model training jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_experiment = Experiment.create(\n",
    "    experiment_name=\"cifar-10-dataset-experiment\", \n",
    "    description=\"objects\", \n",
    "    sagemaker_boto_client=sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_hidden_channel in [32]:\n",
    "    trial_name = f\"cnn-training-job-{num_hidden_channel}-hidden-channels-{int(time.time())}\"\n",
    "    cnn_trial = Trial.create(\n",
    "        trial_name=trial_name, \n",
    "        experiment_name=cifar_experiment.experiment_name,\n",
    "        sagemaker_boto_client=sm,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Using HyperParameter Tuner (OPTIONAL)\n",
    " Its is a feature provided by SageMaker. We can provide a range of possible values and the SageMaker will check for the best combination of hyperparameters in that range.\n",
    " A down side to it is that we cannot use Experiment Tracker while using Hyperparameter Tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter, HyperparameterTuner\n",
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(1e-4, 1, scaling_type=\"Logarithmic\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'cifar-10'\n",
    "estimator_parameters = {'entry_point':'cifar_train.py',\n",
    "                        'instance_type': 'ml.m5.2xlarge',\n",
    "                        'instance_count': 1,\n",
    "                        'model_dir': '/opt/ml/model',\n",
    "                        'role': role,\n",
    "                        'output_path': f's3://{BUCKET}/{PREFIX}/cifar_10/out',\n",
    "                        'base_job_name': f'mme-cv-{model_name}',\n",
    "                        'framework_version': TF_FRAMEWORK_VERSION,\n",
    "                        'py_version': 'py37',\n",
    "                        'script_mode': True}\n",
    "model = TensorFlow(**estimator_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"loss\", \"Regex\": \"loss : ([0-9\\\\.]+)\"}]\n",
    "tuner = HyperparameterTuner(\n",
    "    model,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=9,\n",
    "    max_parallel_jobs=5,\n",
    "    objective_type=objective_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit(inputs, wait=True)  # EXPERIMENT CONFIG CANNOT BE USED IN HYPER PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Tuner Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tuner.latest_tuning_job.job_name)\n",
    "boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    ") #tensorflow-training-220627-0556"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Without HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cifar-10'\n",
    "hyperparameters = {'epochs': 1}\n",
    "estimator_parameters = {'entry_point':'cifar_train.py',\n",
    "                        'instance_type': 'ml.m5.2xlarge',\n",
    "                        'instance_count': 1,\n",
    "                        'model_dir': '/opt/ml/model',  # This shouldn't be changed\n",
    "                        'role': role,\n",
    "                        'hyperparameters': hyperparameters,\n",
    "                        'output_path': f's3://{BUCKET}/{PREFIX}/cifar_10/out',\n",
    "                        'base_job_name': f'mme-cv-{model_name}',\n",
    "                        'framework_version': TF_FRAMEWORK_VERSION,\n",
    "                        'py_version': 'py37',\n",
    "                        'script_mode': True}\n",
    "model = TensorFlow(**estimator_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THE TRIAL NAME THAT YOU HAVE CREATED\n",
    "cnn_training_job_name = \"cnn-training-job-{}\".format(int(time.time()))\n",
    "print(cnn_training_job_name)\n",
    "model.fit(inputs, job_name=cnn_training_job_name,\n",
    "        experiment_config={\n",
    "            \"ExperimentName\": \"cifar-10-dataset-experiment\", \n",
    "            \"TrialName\": 'cnn-training-job-32-hidden-channels-1655871250',\n",
    "            \"TrialComponentDisplayName\": \"Training\",\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing Contents of the recorded experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name='cifar-10-dataset-experiment',\n",
    "    sort_by=\"metrics.test:accuracy.max\",\n",
    "    sort_order=\"Descending\",\n",
    "    metric_names=['test:accuracy'],\n",
    "   # parameter_names=['hidden_channels', 'epochs', 'dropout', 'optimizer']\n",
    ")\n",
    "analytic_table = trial_component_analytics.dataframe()\n",
    "analytic_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSIDER USING THE TRAINING JOB NAME THAT YOU HAVE CREATED \n",
    "analytics = TrainingJobAnalytics(training_job_name = 'cnn-training-job-1655871262', metric_names=['test:accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Cleanup (In Case the Experiment is No Longer needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_sme_sdk(experiment):\n",
    "    for trial_summary in experiment.list_trials():\n",
    "        trial = Trial.load(trial_name=trial_summary.trial_name)\n",
    "        for trial_component_summary in trial.list_trial_components():\n",
    "            tc = TrialComponent.load(\n",
    "                trial_component_name=trial_component_summary.trial_component_name)\n",
    "            trial.remove_trial_component(tc)\n",
    "            try:\n",
    "                # comment out to keep trial components\n",
    "                tc.delete()\n",
    "            except:\n",
    "                # tc is associated with another trial\n",
    "                continue\n",
    "            # to prevent throttling\n",
    "            time.sleep(.5)\n",
    "        trial.delete()\n",
    "        experiment_name = experiment.experiment_name\n",
    "    experiment.delete()\n",
    "    print(f\"\\nExperiment {experiment_name} deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_sme_sdk('cifar-10-dataset-experiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Trained Model (Optional, Not To be used if New model is to be deployed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the model path with the path to the .tar.gz file\n",
    "model_path = f's3://{BUCKET}/cv-models/cifar_10/out/cnn-training-job-1655978931/output/model.tar.gz'\n",
    "\n",
    "model = TensorFlowModel(model_data=model_path, role=role, framework_version=\"2.3.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare a Data Capture Config\n",
    "Data Capture Config is used to provide a storage location and storage mechanism for the datas being sent to the deployed endpoint. It is only required to be implemented if we are also implementing Model Monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "data_capture_prefix = \"{}/monitoring/datacapture/\".format(MONITORING_FOLDER)\n",
    "s3_capture_upload_path = \"s3://{}/{}\".format(BUCKET, data_capture_prefix)\n",
    "\n",
    "data_capture_configuration=DataCaptureConfig(\n",
    "        enable_capture=True, sampling_percentage=100, destination_s3_uri=s3_capture_upload_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name=f'tensorflow-cv-{int(time.time())}'\n",
    "predictor = model.deploy(initial_instance_count=1,   # USE tuner.deploy if HyperParameter Tuner has been used.\n",
    "                       instance_type='ml.m5.xlarge',\n",
    "                       endpoint_name=endpoint_name,\n",
    " data_capture_config = data_capture_configuration)\n",
    "print(f\"\\nSuccessfully deployed at {endpoint_name}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "sm.describe_endpoint(EndpointName = endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoking the Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from IPython.display import Image\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "CIFAR10_LABELS = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you are trying to invoke an existing endpoint.\n",
    "from sagemaker.tensorflow.model import TensorFlowPredictor\n",
    "predictor = TensorFlowPredictor(endpoint_name = endpoint_name)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('./data/cifar_10/raw_images/jeep.png', target_size=(32, 32))\n",
    "data = img_to_array(img)\n",
    "data = data.astype('float32')\n",
    "data = data / 255.0\n",
    "data = data.reshape(1, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {'instances': data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = predictor.predict(payload)\n",
    "predicted_label = CIFAR10_LABELS[np.argmax(resp['predictions'])]\n",
    "print(f'Predicted Label: [{predicted_label}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sending Test Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "print(\"Sending test traffic to the endpoint {}. \\nPlease wait...\".format(endpoint_name))\n",
    "\n",
    "flat_list = []\n",
    "for i in range(100):\n",
    "    data = np.array([X_test[i]])\n",
    "    payload = {'instances': data}\n",
    "    resp = predictor.predict(payload)\n",
    "    predicted_label = CIFAR10_LABELS[np.argmax(resp['predictions'])]\n",
    "    flat_list.append(predicted_label)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"Done!\")\n",
    "print(\"predictions: \\t{}\".format(np.array(flat_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Input data is stored in the Data Input Capture Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.Session().client(\"s3\")\n",
    "result = s3_client.list_objects(Bucket=BUCKET, Prefix=data_capture_prefix)\n",
    "capture_files = [capture_file.get(\"Key\") for capture_file in result.get(\"Contents\")]\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\n \".join(capture_files))\n",
    "print(BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare baseline Dataset\n",
    "To implement Model Monitoring, we also need to provide a Baseline value. Generally the Training data itself is used as the baseline dataset.\n",
    "The baseline data has to be a CSV or a JSON and should contain the fields: probability, prediction, label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_dataset = \"validation_with_predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([X_test[i]])\n",
    "    payload = {'instances': data}\n",
    "    resp = predictor.predict(payload)\n",
    "    predicted_label = CIFAR10_LABELS[np.argmax(resp['predictions'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open(f\"{validate_dataset}\", \"w\") as baseline_file:\n",
    "    baseline_file.write(\"probability,prediction,label\\n\")  # our header\n",
    "    for i in range(1000):\n",
    "        data = np.array([X_train[i]])\n",
    "        payload = {'instances': data}\n",
    "        resp = predictor.predict(payload)\n",
    "        probability = max(resp['predictions'][0])\n",
    "        prediction = np.argmax(resp['predictions'])\n",
    "        label = y_train[i][0]\n",
    "        \n",
    "        baseline_file.write(f\"{probability},{prediction},{label}\\n\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy the File to a S3 Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp ./validation_with_predictions.csv s3://{BUCKET}/DEMO-tf2-ModelMonitor/monitoring/baseline/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL MONITORING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Monitoring requires endpoint to be invoked conituously while also generating corresponding ground truth for the input dataset. Thus we generate a network traffic at the endpoint and also generate a corresponding ground truth for the given inputs. As the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "MONITORING_FOLDER = 'DEMO-tf2-ModelMonitor'\n",
    "BUCKET = 'sagemaker-us-east-1-949263681218'\n",
    "data_capture_prefix = \"{}/monitoring/ground_truth\".format(MONITORING_FOLDER)\n",
    "ground_truth_upload_path = \"s3://{}/{}\".format(BUCKET, data_capture_prefix)\n",
    "\n",
    "def generate_load_and_ground_truth():\n",
    "    df = pd.read_csv('validation_with_predictions.csv')\n",
    "    gt_records = []\n",
    "    for i, row in df.iterrows():\n",
    "        suffix = uuid.uuid1().hex\n",
    "        inference_id = f'{i}-{suffix}'\n",
    "        data = np.array([X_test[i]])\n",
    "        payload = {'instances': data}\n",
    "        args = {'InferenceId': inference_id}\n",
    "        out = predictor.predict(data = payload, initial_args = args)\n",
    "        gt_records.append(str({\n",
    "            \"groundTruthData\": {\n",
    "                \"data\": str(df['label'][i]),\n",
    "                \"encoding\": 'CSV',\n",
    "            },\n",
    "            \"eventMetadata\": {\n",
    "                \"eventId\": str(inference_id),\n",
    "            },\n",
    "            \"eventVersion\": \"0\",\n",
    "        }))\n",
    "    upload_ground_truth(gt_records, ground_truth_upload_path, datetime.utcnow())\n",
    "\n",
    "\n",
    "def upload_ground_truth(records, path, upload_time):\n",
    "    data_to_upload = \",\".join(records)\n",
    "    data_to_upload = data_to_upload\n",
    "    target_s3_uri = f\"{path}/{upload_time:%Y/%m/%d/%H/%M%S}.jsonl\"  # This Datewise Folder Hierarchy is a must. s3://bucket/prefixyyyy/mm/dd/hh\n",
    "    print(f\"Uploading {len(records)} records to\", target_s3_uri)\n",
    "    S3Uploader.upload_string_as_file_body(data_to_upload, target_s3_uri)\n",
    "\n",
    "\n",
    "def generate_load_and_ground_truth_forever():\n",
    "    # for _ in range(2):\n",
    "    while True:\n",
    "        generate_load_and_ground_truth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "thread = Thread(target=generate_load_and_ground_truth_forever)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model Quality Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import ModelQualityMonitor, EndpointInput, DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_default_monitor = ModelQualityMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate constraints and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job_name = f\"ModelQualityMonitor-test-{datetime.utcnow():%Y-%m-%d-%H-%M}\"\n",
    "baseline_data_uri = f's3://{BUCKET}/{MONITORING_FOLDER}/monitoring/baseline'\n",
    "baseline_data_output_uri = f's3://{BUCKET}/{MONITORING_FOLDER}/monitoring/baseline/output'\n",
    "job = my_default_monitor.suggest_baseline(\n",
    "    job_name = baseline_job_name,\n",
    "    baseline_dataset=baseline_data_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=baseline_data_output_uri,\n",
    "    problem_type = 'MulticlassClassification',\n",
    "    inference_attribute=\"prediction\",\n",
    "    probability_attribute=\"probability\",\n",
    "    ground_truth_attribute=\"label\"\n",
    ")\n",
    "job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job = my_default_monitor.latest_baselining_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the constraints and Statistics Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "schema_df = pd.io.json.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_df = pd.io.json.json_normalize(\n",
    "    baseline_job.suggested_constraints().body_dict[\"features\"]\n",
    ")\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare a Function which handles the input data on the endpoint before monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocessing.py\n",
    "import json\n",
    "\n",
    "def preprocess_handler(inference_record):\n",
    "    input_dict = json.loads(inference_record.endpoint_input.data)\n",
    "    output_dict = json.loads(inference_record.endpoint_output.data)\n",
    "    input_data = str(input_dict['instances'].reshape(3072))[1:-1]\n",
    "    output_data = str(np.argmax(output_dict['predictions'][0]))\n",
    "    return_dict = {'prediction000':output_data, 'feature000':input_data}\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_s3_dest_path = f\"s3://{BUCKET}/{MONITORING_FOLDER}/monitoring/preprocessor\"\n",
    "preprocessor_s3_dest = sagemaker.s3.S3Uploader.upload(\"preprocessing.py\", preprocessor_s3_dest_path)\n",
    "print(preprocessor_s3_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "from time import gmtime, strftime\n",
    "\n",
    "s3_report_path = 's3://{BUCKET}/{MONITORING_FOLDER}/monitoring/preprocessor/processed_output'\n",
    "mon_schedule_name = \"DEMO-tf2-model-monitor-schedule-\" + strftime(\"%Y%m%d-%H%M%S\", gmtime())\n",
    "my_default_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name,\n",
    "    endpoint_input=predictor.endpoint,\n",
    "    record_preprocessor_script=preprocessor_s3_dest,\n",
    "    output_s3_uri=s3_report_path,\n",
    "    statistics=my_default_monitor.baseline_statistics(),\n",
    "    constraints=my_default_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "thread = Thread(target=generate_load_and_ground_truth_forever)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "sm = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.list_endpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name='tensorflow-cv-1656302831'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete Monitoring Schedules related to The Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.list_monitoring_schedules(EndpointName = endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MonitoringScheduleArn': 'arn:aws:sagemaker:us-east-1:949263681218:monitoring-schedule/demo-tf2-model-monitor-schedule-20220627-073726',\n",
       " 'MonitoringScheduleName': 'DEMO-tf2-model-monitor-schedule-20220627-073726',\n",
       " 'MonitoringScheduleStatus': 'Scheduled',\n",
       " 'MonitoringType': 'DataQuality',\n",
       " 'CreationTime': datetime.datetime(2022, 6, 27, 7, 37, 27, 456000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2022, 6, 27, 9, 6, 12, 538000, tzinfo=tzlocal()),\n",
       " 'MonitoringScheduleConfig': {'ScheduleConfig': {'ScheduleExpression': 'cron(0 * ? * * *)'},\n",
       "  'MonitoringJobDefinitionName': 'data-quality-job-definition-2022-06-27-07-37-27-181',\n",
       "  'MonitoringType': 'DataQuality'},\n",
       " 'EndpointName': 'tensorflow-cv-1656312038',\n",
       " 'LastMonitoringExecutionSummary': {'MonitoringScheduleName': 'DEMO-tf2-model-monitor-schedule-20220627-073726',\n",
       "  'ScheduledTime': datetime.datetime(2022, 6, 27, 9, 0, tzinfo=tzlocal()),\n",
       "  'CreationTime': datetime.datetime(2022, 6, 27, 9, 5, 50, 205000, tzinfo=tzlocal()),\n",
       "  'LastModifiedTime': datetime.datetime(2022, 6, 27, 9, 6, 12, 523000, tzinfo=tzlocal()),\n",
       "  'MonitoringExecutionStatus': 'Failed',\n",
       "  'EndpointName': 'tensorflow-cv-1656312038',\n",
       "  'FailureReason': 'Job inputs had no data'},\n",
       " 'ResponseMetadata': {'RequestId': '85f15af9-6e46-4480-ba33-c20d71c666fa',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '85f15af9-6e46-4480-ba33-c20d71c666fa',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '921',\n",
       "   'date': 'Mon, 27 Jun 2022 09:11:08 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.describe_monitoring_schedule(MonitoringScheduleName = 'DEMO-tf2-model-monitor-schedule-20220627-073726')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.delete_monitoring_schedule(MonitoringScheduleName = 'DEMO-tf2-model-monitor-schedule-2022-06-27-04-43-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
